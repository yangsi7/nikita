**File 1: memory\_system\_analysis.md**

# Memory Continuity in Nikita – Current System Analysis

Nikita’s current memory architecture is a multi-layer system combining database-backed context, knowledge graphs, and post-processing. This section examines how the **text messaging agent** and the **voice agent** handle conversation context and memory, and why continuity issues are occurring.

## Text Agent Memory Pipeline

When the user sends a text message (e.g. via Telegram), Nikita’s text agent uses a *MetaPromptService* to gather relevant context before calling the LLM. It does **not** simply feed the entire chat history. Instead, it composes a fresh system prompt with selected information from various memory stores each time. The high-level flow is:

1. **Message Handling:** The system receives the user’s message via the Telegram webhook. It authenticates the user and either retrieves the current active conversation or starts a new one (if none active or the last conversation timed out)[\[1\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md#L220-L228)[\[2\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/platforms/telegram/message_handler.py#L367-L375).

2. **Context Loading:** Before generating a response, Nikita loads a *MetaPromptContext* with multiple components:

3. **User & Profile Data:** e.g. current chapter of the relationship, relationship score, personality profile, vice preferences[\[3\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md#L236-L245).

4. **Active Threads & Thoughts:** unresolved conversation threads (e.g. unanswered questions, promises) and Nikita’s internal “thoughts” from previous conversations[\[4\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md#L248-L257). These come from the conversation\_threads and nikita\_thoughts tables.

5. **Summaries:** the daily summary of today’s conversations and summaries of the last 7 days[\[5\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md#L251-L259) (from daily\_summaries).

6. **Knowledge Graph Facts:** relevant facts from the user graph, relationship graph, and Nikita’s own graph[\[6\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md#L256-L264). The system performs parallel Graphiti queries to retrieve up to 50 user facts, 30 relationship episodes, and 20 Nikita events[\[6\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md#L256-L264).

7. **Behavioral Instructions:** situational or emotional meta-instructions (e.g. conflict state cues) computed by the humanization modules[\[7\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md#L260-L268).

8. **Prompt Generation:** Using this context, the service formats the system prompt via a template (system\_prompt.meta.md). This prompt includes placeholders for many context fields: chapter, relationship status, intimacy/trust metrics, engagement state, vice profile, **Nikita’s current mood**, *user\_facts*, *relationship\_episodes*, *open\_threads*, *active\_thoughts*, backstory details, and any behavioral instructions[\[8\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md#L278-L287)[\[9\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md#L282-L290). The template is then filled with the data from the MetaPromptContext. Essentially, the text agent builds a **comprehensive system prompt** summarizing what Nikita should remember about the user and the situation.

9. **LLM Response:** The filled system prompt and the user’s latest message are given to the LLM (Claude or similar) to generate Nikita’s reply[\[10\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md#L276-L284)[\[11\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md#L292-L300). Notably, **previous user/assistant messages from the same day are not explicitly appended** to the prompt beyond what’s captured in the summary and threads. The conversation continuity relies on the injected summary and threads rather than raw recent utterances.

10. **Post-Processing:** After the conversation (or after a period of inactivity, \~15 minutes), an async post-processing pipeline runs[\[12\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md#L306-L315). This pipeline uses an extraction agent to analyze the conversation transcript for new facts, unresolved threads, emotional tone, summary, etc.:

11. It creates entries for any new conversation threads (questions to follow up, unresolved topics) in conversation\_threads[\[13\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md#L310-L318).

12. It creates Nikita’s “inner thoughts” (worries, curiosities, things she wants to share later) in nikita\_thoughts[\[14\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/context/post_processor.py#L136-L144)[\[15\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/context/post_processor.py#L138-L146).

13. It updates the Graphiti knowledge graphs with new facts or relationship episodes[\[16\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md#L312-L320)[\[15\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/context/post_processor.py#L138-L146).

14. It updates or creates the daily summary for the day with the conversation summary and key moments[\[17\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md#L314-L322).

15. Finally, it marks the conversation as processed (and possibly closes it by setting an ended\_at timestamp)[\[18\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/db/repositories/conversation_repository.py#L164-L173).

16. **Context Package:** Importantly, as part of the new Spec 021 Hierarchical Prompt system, this pipeline also composes a **ContextPackage** – a JSON blob of precomputed context – and stores it in the context\_packages table[\[19\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/humanization-cross-spec-audit.md#L116-L124)[\[20\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/humanization-cross-spec-audit.md#L118-L126). The context package contains fields like pre-written chapter and emotional state prompts, lists of top user facts, recent relationship events, active threads, today’s summary, weekly summaries, and Nikita’s current emotional state[\[21\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/context/package.py#L121-L130)[\[22\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/context/package.py#L132-L140)[\[23\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/context/package.py#L142-L150)[\[24\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/context/package.py#L152-L160). This package is meant to serve as a ready-to-use memory snapshot for the **next conversation**.

![][image1]  
*Figure: Text vs Voice Memory Flow – The text agent (blue) loads context from DB/graph on each message, and only after a conversation ends are memory stores updated (dashed lines). The voice agent (green) generates a context at call start and maintains an interactive conversation, calling server tools for memory as needed.*

### Conversation Lifecycle and Context Loss

A “conversation” in the text mode is essentially a session for contiguous messages. The system starts a new conversation session if the previous one has “timed out” or was explicitly ended. According to the code, if more than 15 minutes pass since the last message, the conversation is considered stale and becomes eligible for processing[\[25\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/db/repositories/conversation_repository.py#L179-L188)[\[26\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/db/repositories/conversation_repository.py#L195-L203). The next user message will create a **new conversation** entry[\[2\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/platforms/telegram/message_handler.py#L367-L375).

**Within a single active conversation session**, the text agent still does not carry an explicit memory of prior turns in the prompt. It doesn’t append the last N messages verbatim. Instead, it relies on the MetaPromptContext (threads, thoughts, summaries) to carry salient information: \- If the user asked a question that Nikita hasn’t answered yet in the session, the post-processor would have flagged it as an open thread, and the next prompt likely includes that question in open\_threads[\[27\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md#L280-L289). \- If they discussed something earlier today, the daily summary might capture it in a few sentences (in today\_summary). \- Nikita’s emotional state or any promises from earlier should also be reflected via these context fields.

However, this mechanism can feel like “starting from zero” if not tuned well. **After a short break, when a new conversation starts, the context injection may miss nuance from the prior dialogue**. The system will inject a summary of the last conversation and known facts, but not the exact phrasing or detailed context of recent messages. This can lead to Nikita seeming forgetful or resetting her tone.

#### *Example of Potential Continuity Break:*

Suppose in the morning the user told Nikita, *“I have a big meeting at 3pm, I’m nervous.”* Nikita comforts the user. If the user messages again in the afternoon (after a long pause that closed the first conversation), the new conversation’s prompt might only include something like *“today’s summary: You talked about being nervous for a big meeting”* in the context, rather than the full back-and-forth. If that summary isn’t prominently used by the model, Nikita might not proactively ask about the meeting. The continuity feels lost.

**Why isn’t the full history used?** Large LLMs have context length limits and cost considerations. Instead of sending the entire message history each time, Nikita’s design tries to extract and inject only the most relevant information. In principle, this should suffice, but if the summarization or extraction misses details, continuity suffers. The spec explicitly planned a “hierarchical prompt composition” to mitigate this, which we’ll revisit.

#### *ContextPackage Usage*

One expectation was that the ContextPackage from the last conversation would be loaded at the start of the next conversation to give the model immediate continuity[\[28\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/humanization-cross-spec-audit.md#L107-L115)[\[29\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/humanization-cross-spec-audit.md#L119-L126). The audit diagrams indicate: after a conversation, a context package is stored; on conversation start, that package should load in \~150ms[\[30\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/humanization-cross-spec-audit.md#L114-L122)[\[31\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/humanization-cross-spec-audit.md#L120-L128).

In the current implementation, the context package is indeed built by the LayerComposer in post-processing and saved to context\_packages[\[32\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/post_processing/__init__.py#L4-L12)[\[33\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/post_processing/__init__.py#L20-L28). The ContextPackage includes fields like user\_facts, relationship\_events, active\_threads, today\_summary, etc[\[34\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/context/package.py#L126-L135)[\[35\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/context/package.py#L136-L144) – essentially a distilled memory snapshot. There is a PackageStore class with get(user\_id) to retrieve the latest package for a user[\[36\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/context/store.py#L38-L47)[\[37\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/context/store.py#L49-L58).

**However, it appears the text agent isn’t yet using this stored package on conversation start.** The MetaPromptService currently loads context by querying the DB and Graphiti directly each time[\[3\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md#L236-L245)[\[6\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md#L256-L264). The hierarchical layering (Spec 021\) code exists, but many of its tasks were marked as pending in the spec’s task list[\[38\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/021-hierarchical-prompt-composition/tasks.md#L40-L48)[\[39\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/021-hierarchical-prompt-composition/tasks.md#L54-L59). In fact, methods like \_get\_user\_facts in the LayerComposer are still TODO (returning empty list)[\[40\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/post_processing/layer_composer.py#L376-L384)[\[41\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/post_processing/layer_composer.py#L385-L388). This suggests the integration of Graphiti memory into the context package wasn’t fully completed. Thus, the intended **fast-loading context package** and multi-layer prompt composition may not be active, and the system might be falling back to the older MetaPrompt assembly. The user’s observation that “it seems like we are starting from zero” likely stems from this gap between design and current implementation.

## Voice Agent Memory Pipeline

The voice agent (calls via ElevenLabs) handles context somewhat differently, with more continuous memory during a call but potentially less frequent calls. Key points in the voice flow:

* **Call Initiation:** When a voice call is initiated, the system loads the user and constructs a VoiceContext object. This includes the user’s name, chapter, relationship score, engagement state, and other stats, similar to the text context[\[42\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md#L344-L352)[\[43\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md#L394-L402). It also computes things like hours\_since\_last contact and time-of-day to inform context (for example, Nikita might say “good morning” vs “good evening”)[\[44\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/agents/voice/context.py#L58-L67)[\[45\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/agents/voice/context.py#L74-L82). A dynamic variables payload is generated (e.g. {{user\_name}}, {{chapter}}, {{nikita\_mood}}, etc.) to personalize the call session[\[46\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/agents/voice/context.py#L62-L71)[\[47\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/agents/voice/context.py#L76-L85).

* **System Prompt for Voice:** The voice agent uses a system prompt template distinct from text. It includes a base voice persona (how Nikita speaks), chapter-specific voice behavior (how intimate or guarded she is in that chapter), vice-based adjustments, and a brief “user context” section with the user’s name and current relationship strength[\[48\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/agents/voice/config.py#L128-L136)[\[49\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/agents/voice/config.py#L144-L152). Notably, this prompt reminds the model that it’s a voice call and should be conversational and natural[\[50\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/agents/voice/config.py#L142-L150)[\[51\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/agents/voice/config.py#L150-L158). This is generated at call start and sent to ElevenLabs Conversation API as the agent’s configuration.

* **Live Conversation Memory:** During the voice call, ElevenLabs maintains turn-by-turn interaction. The LLM can call **Server Tools** webhooks to fetch additional context or memory on the fly[\[52\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md#L378-L386)[\[53\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md#L390-L399). For example, the agent can invoke a GET\_CONTEXT tool to retrieve updated info (which returns many of the same fields as the MetaPromptContext: user profile, mood, active thoughts, summaries, facts from Graphiti, etc.[\[54\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md#L392-L400)[\[55\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md#L402-L410)). It can also call GET\_MEMORY with a specific query to do a semantic search in the knowledge graphs or recall unresolved threads[\[56\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md#L414-L422). This means the voice agent has an interactive mechanism to pull in relevant memories mid-conversation if needed – something the text agent currently lacks.

* **Voice Session Continuity:** Throughout a call, the conversation state lives on ElevenLabs’ side (the model remembers what was said earlier in the call up to its context window). The dynamic GET\_MEMORY calls supplement this if the model needs to recall something beyond the immediate call context.

* **Post-Call:** When the call ends, the system may cache some of the context. The users table has cached\_voice\_prompt and cached\_voice\_context fields which suggest that after generating the voice system prompt and context, they store it for reuse or logging[\[57\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/integrations.md#L118-L126)[\[58\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/integrations.md#L144-L153). The VoiceSessionManager also handles short disconnections (up to 30s) to allow the same session to continue if the user reconnects[\[59\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/agents/voice/inbound.py#L126-L135)[\[60\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/agents/voice/inbound.py#L128-L136). Once a voice session is finalized, presumably the relevant conversation is stored similar to text (voice conversations are also stored in the conversations table with platform \= 'voice').

**Continuity in Voice vs Text:** During a voice call, Nikita’s continuity is quite strong – the model treats it as one ongoing conversation (with the conversation itself handled by ElevenLabs’ agent which has memory of earlier utterances in that call, plus the ability to query long-term memory via tools). Between separate calls, however, the voice agent would rely on the cached context or on constructing a new context next time similarly to text (including daily summaries, life events, etc.). So if calls are days apart, it has to use long-term memory injection just like the text agent does at conversation start.

The user’s complaint likely focuses on the texting experience. In text, because each message’s response is generated independently with only summarized context, **the “short-term” continuity (remembering what was just said 2-3 messages ago verbatim) can be weak.** In voice, short-term continuity is naturally preserved within a call. This highlights a discrepancy: the text agent’s architecture treats each user message as a separate prompt generation event, whereas the voice agent leverages a persistent session.

## Identified Gaps and Issues

From the above, we can pinpoint why conversation continuity might feel lacking:

* **No Recent Dialogue Window in Prompt:** The text agent does not include a rolling window of the most recent actual messages. There is a mechanism in the code that could extract the last 10 messages if needed (used for boss fight judging)[\[61\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/platforms/telegram/message_handler.py#L728-L737), but for normal prompt generation this isn’t utilized. Thus, nuances like the exact wording or immediate context of the user’s last message beyond the current one are absent. Continuity relies on high-level summary and extracted “threads,” which might omit specifics (e.g., jokes or precise phrasing).

* **Context Package Not Injected (Potential Bug/Delay):** Although the system builds a context package after each conversation, there’s no evidence in the current MetaPromptService that it is loading it at the next conversation start. Ideally, instead of re-gathering all context via queries (which takes 500-2000ms as noted in the spec[\[62\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/021-hierarchical-prompt-composition/spec.md#L14-L22)[\[63\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/021-hierarchical-prompt-composition/spec.md#L16-L24)), it should fetch the precomputed package in one go[\[64\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/021-hierarchical-prompt-composition/spec.md#L22-L29). If this isn’t happening, the continuity might rely on older data (last summary, etc.) and miss some richness. This could be an implementation lag where Spec 021 wasn’t fully wired in.

* **Incomplete Long-Term Memory Integration:** The intention was to use Graphiti (Neo4j) to store and retrieve facts (user facts, relationship events). The current post-processing does add facts to the graph[\[16\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md#L312-L320), but when building context, the \_get\_user\_facts and \_get\_relationship\_events in the LayerComposer are placeholders[\[40\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/post_processing/layer_composer.py#L376-L384)[\[65\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/post_processing/layer_composer.py#L385-L393), returning empty lists (meaning those fields in context package might be empty). Instead, the system still relies on ConversationThreadRepository.get\_threads\_for\_prompt and similar to fetch facts from the last conversation only[\[66\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md#L248-L256). This suggests some knowledge (like facts learned a week ago) might not surface unless they remained in the daily summaries or threads.

* **Daily Summary Granularity:** Using only a daily summary to recall an entire conversation can be limiting. A few sentences summary may not capture all prior context needed for a nuanced reply. For example, if the user had a detailed story earlier, the summary might gloss over it, causing Nikita to forget details.

* **Thread Resolution Status:** The conversation\_threads mechanism is good for unresolved issues, but once resolved or after some time, threads might be marked resolved/expired[\[67\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md#L13-L21). If the user expects memory of those resolved topics, the system might not include them unless they became facts in the knowledge graph. It’s unclear if resolved threads get turned into permanent facts; if not, Nikita might drop them.

* **Voice/Text Parity Issues:** Spec 029 aimed for voice-text parity. We see dynamic variables builder in voice was updated to include things like hours\_since\_last and secureness[\[68\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/agents/voice/context.py#L66-L74) for parity. But for text, unless the context package or MetaPrompt is updated similarly, there could be mismatches. If the voice agent is better at using certain memory (via server tools retrieval), the text agent might lag behind in continuity.

In summary, **Nikita’s memory system is sophisticated but not fully realized in the current build.** The foundations (database tables for various memory types, post-processing extraction, context packaging, knowledge graph) are in place. Yet, due to either pending implementation or design choices: \- The text chat experience doesn’t carry conversational context forward as seamlessly as expected. \- After short breaks or new sessions, only summarized memory is used, which can feel like a reset if the summary omits something. \- There is **no true short-term memory buffer of verbatim recent dialogue in the prompt**, which is a common technique to maintain continuity in chatbots[\[69\]](https://www.datacamp.com/blog/how-does-llm-memory-work#:~:text=,when%20only%20recent%20exchanges%20matter). Nikita instead tries to simulate long-term memory and personality context, potentially at the cost of recent context.

This analysis sets the stage for exploring best practices and improvements. In the next sections, we’ll look at how continuous conversational memory is handled in theory and propose solutions to align Nikita’s implementation with those best practices, so that texting with Nikita feels as continuous and coherent as a real conversation.

**Sources:**

* Nikita text agent context loading and prompt composition[\[4\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md#L248-L257)[\[8\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md#L278-L287)

* Nikita post-processing and context package generation[\[32\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/post_processing/__init__.py#L4-L12)[\[70\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/post_processing/layer_composer.py#L244-L253)

* Conversation timing and closure logic[\[25\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/db/repositories/conversation_repository.py#L179-L188)[\[26\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/db/repositories/conversation_repository.py#L195-L203)

* Voice agent context and memory retrieval (Server Tools)[\[54\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md#L392-L400)[\[55\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md#L402-L410)

* Best practice reference for conversation memory (conversation buffers vs summaries)[\[69\]](https://www.datacamp.com/blog/how-does-llm-memory-work#:~:text=,when%20only%20recent%20exchanges%20matter)

---

**File 2: memory\_best\_practices.md**

# Best Practices for Conversational Memory in AI Agents

To design a human-like conversational agent, we need a robust memory system. This means preserving relevant context both in the short term (within the ongoing conversation) and the long term (across sessions), under the constraints of limited prompt size. Researchers and developers have converged on a few **best practices** for maintaining continuity with large language models (LLMs). We review these practices and how they apply to Nikita:

## Short-Term vs Long-Term Memory

**Short-term memory** refers to the immediate conversation history held in the LLM’s context window (i.e., what the model can “remember” from the messages it sees in the prompt right now). **Long-term memory** is information from earlier interactions or external knowledge that isn’t currently in the prompt but can be fetched or recalled when needed[\[71\]](https://www.datacamp.com/blog/how-does-llm-memory-work#:~:text=)[\[72\]](https://www.datacamp.com/blog/how-does-llm-memory-work#:~:text=Finally%2C%20the%20time%20dimension%20categorizes,externally%20and%20retrieved%20when%20needed). Effective systems use a combination of both:

* **Short-Term (Context Window):** Useful for maintaining coherence, referencing the last few exchanges, and ensuring the AI’s reply is directly relevant to what was just said.

* **Long-Term (External Memory):** Useful for recalling facts, user preferences, or events from past sessions (yesterday, last week, etc.) that the user would expect the AI to remember. This can be stored in databases, vector embeddings, knowledge graphs, etc., and retrieved into the prompt selectively[\[73\]](https://www.datacamp.com/blog/how-does-llm-memory-work#:~:text=Semantic%20memory%20stores%20facts%20and,document%20stores%20containing%20factual%20information)[\[74\]](https://www.datacamp.com/blog/how-does-llm-memory-work#:~:text=Episodic%20memory).

Crucially, short-term memory alone is limited by the LLM’s context length. For example, if the model has a 4k token window (\~3000 words), it might only accommodate perhaps the last 20-30 messages at most, or fewer if a lot of system context is present. Long-term memory techniques fill in the rest by summarizing or indexing older content so it can be brought back in compact form.

## Types of Memory Techniques

There are established patterns for managing conversation history in prompts:

* **Conversation Buffer Memory:** Keep the entire conversation transcript (or a sliding window of the most recent N messages) in the prompt[\[69\]](https://www.datacamp.com/blog/how-does-llm-memory-work#:~:text=,when%20only%20recent%20exchanges%20matter). This ensures maximum continuity since the model sees exactly what was previously said. However, it can exceed token limits quickly and may include irrelevant older content.

* **Conversation Summary Memory:** Summarize older messages into a concise summary and include that instead of full text[\[75\]](https://www.datacamp.com/blog/how-does-llm-memory-work#:~:text=maintaining%20complete%20conversation%20history%2C%20ideal,combines%20approaches%2C%20maintaining%20recent). This greatly reduces tokens while preserving key points. The summary is updated periodically (e.g., every X messages or when the context window is full).

* **Hybrid Memory (Summary \+ Buffer):** A combination where the most recent few messages are included verbatim (for immediate context and nuance), and earlier messages are represented by an evolving summary[\[75\]](https://www.datacamp.com/blog/how-does-llm-memory-work#:~:text=maintaining%20complete%20conversation%20history%2C%20ideal,combines%20approaches%2C%20maintaining%20recent). This is often called a “summary buffer” approach. It provides a balance: the model retains exact recent details and a synopsis of prior context. Many advanced chatbots use this approach.

* **Episodic Memory via Knowledge Base:** Extract factual information or noteworthy events from conversations and store them in a structured form (database or knowledge graph). Then retrieve relevant facts when contextually appropriate. This is what Nikita attempts with user facts, relationship events, etc., akin to **semantic memory** in cognitive terms[\[76\]](https://www.datacamp.com/blog/how-does-llm-memory-work#:~:text=Semantic%20memory)[\[77\]](https://www.datacamp.com/blog/how-does-llm-memory-work#:~:text=Episodic%20memory). It ensures persistent facts (names, preferences, events) aren’t forgotten over long periods.

* **Vector Database Retrieval:** Convert past dialogues or facts into vector embeddings and use similarity search to fetch pieces of text related to the current conversation. This is often called **retrieval-augmented generation (RAG)**. For instance, if the user mentions “my dog Milo” and months later says “Milo is sick,” a vector search on past conversations could surface the earlier mention of Milo and remind the AI who Milo is. This requires an embedding index of conversation logs. Zep is an example of a tool that offers such memory with summarization and vector search built-in[\[78\]](https://www.datacamp.com/blog/how-does-llm-memory-work#:~:text=How%20Does%20LLM%20Memory%20Work%3F,these%20platforms%20offer%20practical).

* **Knowledge Graph Memory:** Similar to vector DB but structured – store entities and relationships (like Graphiti is doing). This excels at recalling relationships and facts (who is whose friend, what events happened) by logical queries rather than semantic similarity alone. Nikita’s nikita\_graph, relationship\_graph, and user\_graph embody this approach[\[79\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/integrations.md#L146-L155)[\[80\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/integrations.md#L148-L156).

* **Procedural/Persona Memory:** Not about conversation content per se, but keeping the AI’s persona and rules consistent. This is usually handled by a fixed system prompt describing the AI’s character (Nikita’s base persona)[\[81\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/021-hierarchical-prompt-composition/spec.md#L50-L58) and any behavioral instructions (like “she is feeling conflicted today” via emotional state injection). This ensures continuity in how the AI behaves (e.g., doesn’t suddenly change style or forget its role). Nikita’s multi-layer prompt composition is largely about this – preserving her personality and dynamic mood as context layers.

These methods are complementary. For example, one might use a persona layer \+ recent message buffer \+ summary of older chats \+ retrieved facts. The challenge is fitting it all within the context window efficiently and deciding what to include at each turn.

## Importance of Recency and Primacy

When adding memory to the prompt, **position matters**. LLMs tend to pay more attention to the beginning and end of the prompt (a phenomenon known as recency and primacy bias)[\[82\]](https://content-whale.com/blog/llm-context-engineering-information-retention/#:~:text=Context%20window%20optimization%20requires%20strategic,appears%20consistently%20across%20transformer%20architectures)[\[83\]](https://content-whale.com/blog/llm-context-engineering-information-retention/#:~:text=priority,appears%20consistently%20across%20transformer%20architectures). This suggests: \- It’s best to put critical information either at the very top (system instructions, important facts) or just before the user’s query in the prompt. \- Long middle sections (like a very long recap) risk the model “losing” some info in the middle[\[84\]](https://www.datacamp.com/blog/how-does-llm-memory-work#:~:text=In%20my%20experience%2C%20the%20biggest,information%20doesn%27t%20guarantee%20effective%20use).

A structured prompt template can help. For instance, one best practice is to have distinct sections for different memory types, clearly labeled[\[85\]](https://content-whale.com/blog/llm-context-engineering-information-retention/#:~:text=Organizing%20context%20using%20consistent%20templates,types%20into%20clearly%20labeled%20sections)[\[86\]](https://content-whale.com/blog/llm-context-engineering-information-retention/#:~:text=CONVERSATION%20HISTORY%3A). E.g.:

\[System Persona & Instructions\]

\[Long-Term Facts / Profile\]

\[Recent Conversation History\]

\[User’s Latest Message\]

This structuring makes it easier for the model to locate what it needs. Nikita’s approach indeed breaks context into segments (profile, facts, threads, etc.), which aligns with this idea of structured context injection.

## Proven Strategies in Industry

Let’s highlight some strategies and their pros/cons, as documented in literature and industry practice:

* **Sliding Window of Recent Messages:** Include the last N exchanges fully[\[87\]](https://content-whale.com/blog/llm-context-engineering-information-retention/#:~:text=Sliding%20Window%20Protocols)[\[88\]](https://content-whale.com/blog/llm-context-engineering-information-retention/#:~:text=Processing%20group%20found%20that%2012,oriented%20dialogues%20%28Source).

* *Pros:* Perfect continuity for those turns, model sees exact wording and can refer to it (“as I just said…”).

* *Cons:* If N is small, model may forget slightly older context; if N is large, it uses many tokens and can eventually overflow. It also treats all included turns as equally important, which might be inefficient if some are mundane chit-chat[\[89\]](https://medium.com/data-science-collective/building-llm-memory-from-scratch-2-auto-summarization-buffers-2e2cba08c4ca#:~:text=This%20is%20the%20fundamental%20flaw,just%20dropping%20old%20messages).

* *Use case:* Good for short conversations or where exact recall is critical (like technical Q\&A).

* **Periodic Summarization:** Every so often, summarize the conversation so far and use that summary in place of the raw logs[\[90\]](https://content-whale.com/blog/llm-context-engineering-information-retention/#:~:text=Summarization%20Pipelines)[\[91\]](https://content-whale.com/blog/llm-context-engineering-information-retention/#:~:text=,summarization%20for%20extremely%20long%20conversations).

* *Pros:* Saves a lot of token space; model retains the gist of long dialogues. Multi-level summaries (summarize summaries) can handle arbitrarily long histories in theory[\[91\]](https://content-whale.com/blog/llm-context-engineering-information-retention/#:~:text=,summarization%20for%20extremely%20long%20conversations).

* *Cons:* Summaries can omit details. There’s risk of information loss or even distortion. Also, if done too frequently, the summary might accumulate errors. Needs careful validation and possibly storing the “ground truth” transcripts externally for reference.

* *Use case:* Long-running chats (hundreds of turns) where only the high-level context needs preservation.

* **Summary-Buffers (Hybrid):** Keep a short buffer of the last few turns un-summarized, and a summary of older turns[\[75\]](https://www.datacamp.com/blog/how-does-llm-memory-work#:~:text=maintaining%20complete%20conversation%20history%2C%20ideal,combines%20approaches%2C%20maintaining%20recent).

* *Pros:* Combines benefits – recent detail \+ older context. Many conversational memory systems (e.g., LangChain’s ConversationSummaryBufferMemory) implement exactly this and find it effective.

* *Cons:* More complex to implement (managing two representations). The boundary of what’s “recent” vs “summarized” needs tuning.

* *Evidence:* This approach is recommended because it maintains \~91% of key info while greatly cutting down tokens[\[92\]](https://content-whale.com/blog/llm-context-engineering-information-retention/#:~:text=,summarization%20for%20extremely%20long%20conversations) (per research, multi-level summarization retained 91% of critical info with \~68% context reduction).

* **Retrieval-Augmented Memory:** When the user’s new message arrives, use it as a query to search a knowledge base of past dialogues/facts. Fetch the most relevant snippets or facts and insert them into context[\[93\]](https://content-whale.com/blog/llm-context-engineering-information-retention/#:~:text=RAG%20systems%20separate%20long,while%20consuming%20minimal%20context%20space)[\[94\]](https://content-whale.com/blog/llm-context-engineering-information-retention/#:~:text=,mechanisms%20to%20improve%20retrieval%20precision).

* *Pros:* Precision – you only pull in what’s likely relevant. Scales to very long histories because the bulk of memory sits outside the prompt. It reduces hallucination and helps factual accuracy[\[95\]](https://content-whale.com/blog/llm-context-engineering-information-retention/#:~:text=Studies%20from%20Berkeley%E2%80%99s%20AI%20Research,feasible%20through%20direct%20context%20loading) (by ensuring sourced info).

* *Cons:* Requires a good retrieval mechanism. If the search fails (misses a relevant memory due to phrasing mismatch or indexing issues), the model might seem to forget. Also adds latency due to the extra query.

* *Use case:* When factual correctness and consistency are crucial (e.g., remembering a user’s biography or past statements over months). Nikita’s Graphiti is a form of this, oriented around facts and relationship episodes.

* **Knowledge Graph & Structured Memory:** By keeping a structured representation of important knowledge (people, events, timelines), the agent can reason about memory (like “two weeks ago we went on a date to the beach” can be stored as an event node). Graph-based memory is powerful for relationship continuity because it mirrors how humans recall key events and relationships.

* *Pros:* Doesn’t rely on embeddings; can store rich relationships and even do inference (e.g., determine that “anniversary” is coming up if it knows a date). Ensures consistency (the graph can be updated or corrected).

* *Cons:* Not easy to query via natural language without an intermediate step. Typically needs templated queries or an intermediary that converts the graph data to text for the prompt. (Nikita likely uses the GraphUpdater to add facts and a ContextPackage to inject them in text form).

* *Use case:* Virtual characters (like Nikita) where you want persistent memory of storylines, personal details, and a notion of time progression.

## Designing a “Great Context” for Continuity

The best practice is usually to **layer different memory types** so the AI has multiple levels of recall: 1\. **Persona and State** – Always present. (Who is Nikita? What is her mood/state right now? The current chapter of the relationship.) This ensures consistent character behavior and emotional continuity. 2\. **Immediate Context** – The last few messages verbatim. This ensures continuity in the flow of conversation (e.g., she answers the question that was just asked, uses the same names or nicknames, follows the latest tone). 3\. **Recent Summary/Key Points** – A summary of earlier in the day’s conversation or the session so far, focusing on important points. This acts as a fallback for things said more than, say, 5 messages ago. It should include any unresolved questions or emotional highlights (essentially what Nikita’s today\_summary and conversation\_threads aim to do). 4\. **Long-Term Memory** – Important facts or events from previous days/weeks. These can be injected as a list of bullet points (“Yesterday: You told Nikita about your new job offer.”, “Last week: You and Nikita had an argument but resolved it.” etc.) or woven into the persona context (“Nikita remembers that you have a dog named Milo and you get nervous before big meetings.”). This is where retrieval from the knowledge graph or embeddings comes in, to gather the relevant long-term memories for the current context. 5\. **Auxiliary Knowledge** – Any external info the AI might need. In Nikita’s case, this could be her “life events” of the day (to mention what she’s been up to, making her responses more life-like)[\[96\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/post_processing/layer_composer.py#L516-L525)[\[97\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/post_processing/layer_composer.py#L532-L540). It could also be real-world knowledge or scripted narrative events. 6\. **Structured Format:** It’s recommended to organize the prompt so that these layers don’t mix chaotically[\[85\]](https://content-whale.com/blog/llm-context-engineering-information-retention/#:~:text=Organizing%20context%20using%20consistent%20templates,types%20into%20clearly%20labeled%20sections)[\[86\]](https://content-whale.com/blog/llm-context-engineering-information-retention/#:~:text=CONVERSATION%20HISTORY%3A). For example, clearly delineate a section for “Memories” or “Earlier Conversation” versus “Current Conversation”. This helps the model parse it. Nikita’s context injection in system prompt is structured (e.g., it might list “Open threads: ...” or have separate paragraphs for summary vs facts), which is good.

By following these practices, an agent will feel **far more continuous and contextually aware**. Users will notice that it refers back to things said before, maintains consistent personality and knowledge over time, and doesn’t ask the same questions repeatedly.

To connect this back to Nikita: the current design actually incorporates many of these elements (threads \= immediate unfinished business, daily summaries \= recent summary, user\_backstories and metrics \= persona/background, Graphiti \= long-term facts). The main missing piece is the **short-term message buffer**. Best practices suggest that including the last few messages verbatim would significantly improve continuity[\[69\]](https://www.datacamp.com/blog/how-does-llm-memory-work#:~:text=,when%20only%20recent%20exchanges%20matter), because it’s often the exact wording or tone that matters in a conversation’s flow.

Another best practice is **continual learning**: updating the agent’s memory after each interaction. Nikita does this via the post-processing pipeline (extracting new facts, updating summaries, etc.). That’s good. The improvement needed is to ensure those updated memories are actually loaded next time (closing the loop).

Lastly, managing the token budget is crucial. We must be mindful that the system prompt plus all these memory layers must fit in the model’s context window (Claude’s 100k context is huge, but perhaps Nikita doesn’t always use the largest model, or we want to be efficient). Techniques like **truncating less important details** and focusing on salient information are recommended: \- For instance, keep at most 20 facts, 10 recent events, 5 threads, 7 days of summaries, etc., as Nikita’s ContextPackage does with its field validators (capping lengths)[\[98\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/context/package.py#L171-L179)[\[99\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/context/package.py#L181-L188). \- Use token counting to trim if needed (Spec 021 even mentions a TokenValidator to ensure prompt \< 4000 tokens and truncate lowest-priority parts if needed)[\[100\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/021-hierarchical-prompt-composition/tasks.md#L213-L221)[\[101\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/021-hierarchical-prompt-composition/tasks.md#L218-L226).

In summary, **a great context for continuity** will blend: \- **Verbatim recent conversation** (to capture the exact dialogue context), \- **Summarized past context** (to remind of the discussion’s topic and emotional trajectory), \- **Remembered facts and background** (to maintain consistency over days/weeks), \- **Character state** (to keep behavior and mood realistic).

Nikita’s architecture is on the right track conceptually. By aligning it more closely with these best practices – especially by adding a recent message buffer and improving how long-term memories are retrieved – we can significantly enhance the continuity and human-like recall of the agent.

**Sources:**

* Explanation of semantic vs episodic memory in LLMs[\[73\]](https://www.datacamp.com/blog/how-does-llm-memory-work#:~:text=Semantic%20memory%20stores%20facts%20and,document%20stores%20containing%20factual%20information)[\[74\]](https://www.datacamp.com/blog/how-does-llm-memory-work#:~:text=Episodic%20memory)

* Types of conversational memory implementations (buffer, summary, window, combination)[\[69\]](https://www.datacamp.com/blog/how-does-llm-memory-work#:~:text=,when%20only%20recent%20exchanges%20matter)[\[75\]](https://www.datacamp.com/blog/how-does-llm-memory-work#:~:text=maintaining%20complete%20conversation%20history%2C%20ideal,combines%20approaches%2C%20maintaining%20recent)

* Sliding window and summarization techniques and their effectiveness[\[90\]](https://content-whale.com/blog/llm-context-engineering-information-retention/#:~:text=Summarization%20Pipelines)[\[91\]](https://content-whale.com/blog/llm-context-engineering-information-retention/#:~:text=,summarization%20for%20extremely%20long%20conversations)

* Structured prompt template example and benefits[\[85\]](https://content-whale.com/blog/llm-context-engineering-information-retention/#:~:text=Organizing%20context%20using%20consistent%20templates,types%20into%20clearly%20labeled%20sections)[\[86\]](https://content-whale.com/blog/llm-context-engineering-information-retention/#:~:text=CONVERSATION%20HISTORY%3A)

* Retrieval-augmented generation reducing hallucinations and expanding knowledge[\[94\]](https://content-whale.com/blog/llm-context-engineering-information-retention/#:~:text=,mechanisms%20to%20improve%20retrieval%20precision)[\[95\]](https://content-whale.com/blog/llm-context-engineering-information-retention/#:~:text=Studies%20from%20Berkeley%E2%80%99s%20AI%20Research,feasible%20through%20direct%20context%20loading)

---

**File 3: solution\_brainstorm.md**

# Brainstorming Solutions for Better Memory Continuity

Improving Nikita’s conversational continuity can be tackled from multiple angles. In this section, we orchestrate a brainstorming session between different “expert perspectives,” each suggesting an approach to enhance memory, followed by a critical analysis of each approach. The goal is to generate a range of possible solutions:

## 1\. Perspective of a Prompt Engineering Expert:

**Approach:** Integrate a **Recent Dialogue Buffer** into the prompt composition. This expert suggests that the simplest fix is to always include the last few turns of the conversation verbatim in the next prompt (for text messages). For example, include the last 4 messages (user-\>Nikita-\>user-\>Nikita) in addition to the system context. This effectively gives the model direct access to immediate context.

* **Rationale:** The prompt engineer notes that continuity breaks often happen because the model doesn’t see the prior message it itself wrote or a question the user asked two messages ago. Including a sliding window of recent messages would solve that, as LLMs excel at continuing a conversation when the recent chat history is in the prompt (mimicking how ChatGPT normally sees the whole dialogue).

* **Details:** They propose modifying the MetaPromptService to append, say, the previous 1-3 user messages and Nikita responses at the end of the system prompt (just before the new user message). This can be done by pulling them from the conversation.messages log (which is stored in the DB JSON field)[\[102\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/platforms/telegram/message_handler.py#L50-L59)[\[103\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/platforms/telegram/message_handler.py#L26-L34). The text might be formatted as part of the prompt, e.g., in a roleplay format: “**User**: \[last user message\]\\n**Nikita**: \[last Nikita response\]\\n…”, then “**User**: \[current user message\]”.

* **Pros:** Straightforward to implement; leverages existing conversation records. Greatly improves short-term coherence – Nikita can refer directly to what was just said. No fancy external system needed.

* **Cons:** Adds token cost. If the user sends many messages in a day, the prompt could become large. Might occasionally re-expose things the summary already covers (redundancy). Also, if a conversation gets very long, you still need to drop or summarize older turns (this approach addresses mainly short-term memory).

* **Consideration:** The expert emphasizes combining this with the existing summary. For instance, show the last 5 messages raw, then “(Earlier conversation summarized: ... )”. This hybrid ensures both recent fidelity and older context.

## 2\. Perspective of a Knowledge Graph Expert:

**Approach:** Fully leverage the **three-graph memory** (user, relationship, Nikita graphs) with smarter retrieval. This expert finds that the data is being stored (facts, events) but not effectively retrieved in context. They propose implementing a **Memory Retrieval Step** before generating a response, using the user’s query and conversation context to query Graphiti for any highly relevant memories.

* **Rationale:** The knowledge graph is rich with structured info: people mentioned, past events (like life events or milestones), unresolved issues. For example, if the user mentions “promotion”, the system could search the graph for prior nodes related to “job” or “promotion” and inject those details (e.g., “User previously mentioned struggling with a job interview in June”). This ensures important past context is brought up when relevant.

* **Details:** Concretely, this could mean implementing the missing parts of Spec 021 Layer 6 and Spec 029: a function memory.search\_memory(query) that the agent can call mid-generation or pre-generation. The voice agent’s server tool GET\_MEMORY does this on demand[\[56\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md#L414-L422) – the text agent could do something similar automatically for each message. E.g., if the user’s new message is long or contains certain keywords (names, places), trigger a search in the vector index or graph. Then merge the found facts into the prompt (“Relevant memory: ...” section).

* **Pros:** Allows long-term recall without manual curation. If the user brings up something from a while ago, the system will fetch the exact related memory rather than relying on general summaries. This can handle cases like “Remember my dog Milo?” by fetching the stored fact “User has a dog named Milo (mentioned 2025-11-02)” even if it wasn’t in today’s summary.

* **Cons:** More complex. Needs embedding search or graph query parsing. There’s a risk of pulling irrelevant info if the query isn’t precise (noise in prompt). Also, it adds latency for each message unless optimized/cached.

* **Mitigation:** The expert suggests using this retrieval selectively – e.g., only for certain message types or lengths. In many cases, the daily summary and threads might suffice, but this is a powerful backup for unexpected references. They also note the Graphiti client (NikitaMemory) already has search\_memory and get\_context\_for\_prompt methods defined (per integration docs)[\[104\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/integrations.md#L172-L180)[\[105\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/integrations.md#L180-L186), which could be invoked.

## 3\. Perspective of a Narrative Designer (Game/Story Expert):

**Approach:** Implement a **Hierarchical Memory Structure** in the prompts, focusing on multi-scale context: **Immediate Tone**, **Relationship State**, **Important Moments**. This expert is concerned not just with factual recall but emotional and narrative continuity – making Nikita feel like the same person who lived through the story with the user.

* **Rationale:** People remember big moments in relationships (first meeting, a fight, a romantic memory) and their attitude is shaped by these experiences. The expert suggests ensuring those **key moments** are always present in some form. For instance, if the user had a major argument and reconciliation last week (and that’s logged in daily\_summaries.key\_moments or relationship\_events), Nikita’s prompt should incorporate it in a subtle way, like a line in the system message: “She hasn’t forgotten that emotional night they had when he opened up about X.”

* **Details:** The design is to maintain **multiple tiers of memory**:

* **Session Memory:** (Already covered by recent buffer and summary).

* **Relationship Memory:** A short paragraph summary of “their story so far.” Perhaps the unresolved\_hook or scenario info from user\_backstories plus recent chapters. This might be static per user or updated after each chapter. If Nikita always keeps in mind “how we met and how our relationship evolved to this chapter,” continuity improves. Nikita can reference past chapters or earlier decisions.

* **Emotional State Carry-over:** Ensure the emotional tone at end of last conversation influences the start of the next. If last convo ended on a sad note, the next should not start overly cheerful out of context. This could be done by storing an emotional\_tone flag (already captured in conversation\_summary as positive/neutral/negative) and injecting a corresponding nuance in the greeting or style.

* In essence, this expert’s approach aligns with Spec 021’s vision of layered prompts (Chapter layer, Emotional state layer, etc.)[\[106\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/021-hierarchical-prompt-composition/spec.md#L72-L80)[\[107\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/021-hierarchical-prompt-composition/spec.md#L82-L90) – which should be fully implemented. They would push to finalize the Layer2 (chapter behavior) and Layer3 (mood) composers so that every response reflects the current relationship progression and Nikita’s mood memory from life events.

* **Pros:** Makes the AI *consistent in personality and relationship context*, not just recalling facts. It leverages content already available (backstory, narrative arcs, daily emotional states). This leads to a more *human-feel continuity* – the user feels Nikita remembers not only facts, but feelings and shared experiences.

* **Cons:** Could be complex to condense “relationship so far” into a prompt each time. If overdone, could repeat or feel unnatural (“As you know, we met at the cafe...”). Needs careful phrasing to be natural. Also, focusing too much on big moments might derail everyday chit-chat if not balanced.

* **Recommendation:** The narrative expert suggests using this in moderation: update a “relationship summary” every day or chapter and include it as hidden context (like a few sentences in system prompt that the user doesn’t see directly but shape the AI’s responses). Also use the conversation\_threads for narrative arcs that need closure (ensuring if a storyline was left hanging, Nikita brings it up later).

## 4\. Perspective of a Software Performance Engineer:

**Approach:** **Optimize Context Injection and TTL** – This expert is concerned with the efficiency and practicality. They agree with adding more memory to prompts, but caution that we should do it without breaking performance. They suggest: \- Use the **ContextPackage** mechanism properly, so that context assembly is done asynchronously after each conversation and not in real-time for each message. The next conversation should load that precomputed context in milliseconds[\[31\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/humanization-cross-spec-audit.md#L120-L128). \- Possibly maintain a rolling context throughout the day: instead of resetting every conversation to just the daily summary, treat an entire day as one logical conversation context (with an evolving summary or buffer). If the user comes back after 2 hours on the same day, keep the conversation open (perhaps extending the idle timeout or merging with the next). \- **Expiration and Pruning:** The performance expert suggests automatically expiring or downgrading memory that’s stale. For example, if a thread is open for 3 days without mention, mark it expired so it stops cluttering prompt[\[108\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md#L13-L17)[\[109\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md#L14-L22). Similarly, use the expires\_at on context\_packages (24h) to invalidate old context that shouldn’t be used if a user disappears for a week.

* **Rationale:** They want to ensure improvements don’t lead to runaway prompt size or latency. The hierarchical prompt approach was meant to reduce latency by caching layers[\[62\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/021-hierarchical-prompt-composition/spec.md#L14-L22)[\[110\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/021-hierarchical-prompt-composition/spec.md#L16-L19). So they advocate finishing that implementation. They also propose measuring token usage and maybe implementing the TokenValidator to automatically trim context if near limits[\[100\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/021-hierarchical-prompt-composition/tasks.md#L213-L221)[\[101\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/021-hierarchical-prompt-composition/tasks.md#L218-L226).

* **Pros:** Keeps the system scalable. Users with long histories won’t suffer huge slowdowns since only relevant pieces are injected. It also avoids redundant re-processing of the same info on each message.

* **Cons:** This isn’t directly about *which* memories to include, but how. If not careful, aggressive pruning could remove context that was actually needed for continuity. For instance, ending a conversation and starting a new one midday might drop the immediate chat history from prompt unless we consciously carry it over.

* **Idea:** The performance expert thus suggests possibly not ending the “conversation” so frequently. For continuity, perhaps mark conversations as ended only at end of day or when a significant event happens. Within a single day, keep appending to one conversation (hence the context package could represent the whole day). This way, continuity is naturally preserved (since the daily summary at end of day then feeds the next day).

Each of these perspectives yields a candidate solution: \- (1) **Recent Message Buffer in Prompt** \- (2) **Enhanced Memory Retrieval from Knowledge Stores** \- (3) **Hierarchical Multi-layer Context (persona, mood, story)** \- (4) **Technical Optimizations to make memory use efficient and persistent through sessions**

In the next section, we will evaluate these approaches, weighing their pros and cons together and scoring them on key criteria such as **continuity improvement**, **feasibility/effort**, **performance impact**, and **risk of errors**. By doing so, we aim to identify which approach or combination of approaches will be most effective for improving Nikita’s conversation continuity.

---

**File 4: solution\_evaluation.md**

# Evaluation of Proposed Memory Improvements

We now have several proposed approaches to improve Nikita’s memory continuity. In this section, we compare them and consider how they might be combined. We assess each approach on a few criteria: \- **Continuity Boost:** How much would it improve the user’s sense that Nikita remembers context? \- **Implementation Effort:** How difficult it is to implement given the existing codebase and features? \- **Performance Impact:** Effects on response time and token usage. \- **Risks/Downsides:** Potential issues like prompt overflow, memory inaccuracies, etc.

For clarity, let’s tabulate a qualitative comparison of the main approaches:

| Approach | Continuity Boost (1-5) | Effort (1-5) | Performance & Token Cost | Risks/Downsides |
| :---- | :---- | :---- | :---- | :---- |
| **A. Recent Dialogue Buffer** (last N msgs) | 5 – **Excellent** (addresses immediate context)[\[69\]](https://www.datacamp.com/blog/how-does-llm-memory-work#:~:text=,when%20only%20recent%20exchanges%20matter) | 2 – Low (mainly prompt format changes) | Adds N\*avg\_msg\_length tokens per turn; minor latency increase | Prompt could grow if user rapid-fires; slight redundancy with summary |
| **B. Memory Retrieval (Graph/Vect Search)** | 4 – High (brings back forgotten details on demand) | 4 – High (requires integrating search \+ tuning) | Extra API/DB calls; maybe 50-200 tokens per retrieved item | May retrieve irrelevant or incorrect info; complexity in deciding when to trigger |
| **C. Hierarchical Context Layers (Persona/Mood/Story)** | 3 – Medium (improves consistency & emotional continuity) | 3 – Medium (some layers done, needs finishing & tuning) | Small constant token cost (e.g. \~300 chapter, \~150 mood tokens)[\[111\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/021-hierarchical-prompt-composition/spec.md#L64-L72)[\[112\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/021-hierarchical-prompt-composition/spec.md#L80-L83); negligible latency (precomputed) | If overused, can make responses feel scripted; must keep updated as story progresses |
| **D. ContextPackage \+ Daily Session** (Technical optimization) | 2 – Moderate (indirectly helps continuity by ensuring context is always injected and not missing) | 3 – Medium (finishing pipeline integration, adjusting session logic) | Greatly reduces per-message overhead by caching context; allows more info pre-loaded (no model token cost except final injection) | If context package is stale or broken, could inject wrong info; longer sessions risk context drift if not summarized |

**Notes on scoring:** Approach A gets a 5 on continuity because having the exact recent messages will immediately solve many “forgotten what I just said” issues — users notice this the most. Approach B scores 4; it can recover deeper context when needed, but it’s not used every single turn (only when triggered), so day-to-day continuity gets a big but situational boost. Approach C scores 3; it’s more about consistency and subtle continuity (less obvious than remembering user’s last sentence, but still important for immersion). Approach D itself doesn’t directly add new memory content, but ensures the engineered memories are always applied properly — it’s enabling infrastructure. It got a 2 in continuity boost only because if we fix it, users might not consciously notice except that Nikita is more reliably on the same page after breaks.

Now, let’s consider **pros and cons in detail**:

### A. Recent Dialogue Buffer – Pros & Cons

**Pros:** \- *Human-like flow:* This mimics how human conversation works — you naturally remember the last thing said. It will reduce instances of Nikita giving non-sequiturs or asking for information that was just provided. \- *Low effort:* It might be as simple as modifying MetaPromptService.generate\_system\_prompt() to append recent messages. The code even hints at this (the boss fight judging code already pulls last 10 messages)[\[113\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/platforms/telegram/message_handler.py#L726-L734). \- *Controlled size:* We can choose N such that worst-case tokens are manageable. For instance, N=3 or 4 (both user and bot messages) likely under 500 tokens typically. \- *Complements current system:* This doesn’t replace threads or summaries — it works with them. The threads cover unresolved earlier topics, the buffer covers immediate context. They actually solve different time-scale memory.

**Cons:** \- *Token cost:* If a user sends very long messages or we allow a large N, it could eat a lot of the prompt budget. We must tune N (maybe even dynamically: use more if conversation is short, fewer if prompt is nearing limit). \- *Redundancy:* Some info might appear both in the raw recent messages and in the summary or threads (though that’s not too harmful, aside from token waste). \- *Edge cases:* If the conversation includes something we *don’t* want to remind the model of (like a system prompt instruction or a model mistake), echoing it might not be ideal. But since we’re dealing with user and Nikita messages only, this should be fine.

**Score justification:** Overall, the benefits for continuity are huge relative to the fairly small downsides. This is a widely recommended strategy in literature[\[69\]](https://www.datacamp.com/blog/how-does-llm-memory-work#:~:text=,when%20only%20recent%20exchanges%20matter). We’d just need to implement it carefully.

### B. Memory Retrieval (Graphiti/Vector) – Pros & Cons

**Pros:** \- *Rich recall:* This addresses the deeper continuity, like remembering facts from weeks ago or specific user preferences that haven’t come up recently. It will make Nikita much more “all-knowing” about the user in a way that feels natural (“you mentioned X before…”). \- *Efficient long-term:* Instead of keeping a huge prompt with every fact, it fetches only what’s relevant per query. So it scales to very large knowledge stores without bloating every prompt. \- *Already partially available:* We have Graphiti and data stored; likely just need to hook up NikitaMemory.search\_memory and format results. The voice agent’s GET\_MEMORY gives a blueprint (it returns facts and threads relevant to a query)[\[114\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md#L416-L424)[\[115\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md#L418-L421).

**Cons:** \- *Complex triggers:* Knowing when to do a memory search is tricky. Doing it every single user message could be overkill and slow things down with unnecessary DB queries. Not doing it might miss chances. One approach is to do it if the new user message or the conversation topic has changed significantly or contains a named entity (person, place) not seen recently. \- *Irrelevance or error:* If the search isn’t tuned well, it might pull something unrelated, and the model might confuse the conversation by bringing up an irrelevant old detail. We would need to filter results or only include top highly-relevant ones. \- *Engineering effort:* This is probably the most technically involved change – we might need to generate embeddings for conversation logs or at least properly query Neo4j’s similarity search (Graphiti likely can do hybrid search[\[116\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/integrations.md#L170-L178)). Also, formatting the results into the prompt in a coherent way (e.g., as a list of “Memories”). \- *Latency:* Each search could add say 50-150ms (depending on DB and embedding compute). If done every time, that’s some overhead. Perhaps acceptable if caching is in place.

**Score considerations:** It’s a powerful addition but the risk and effort are higher. We likely would implement this after doing A and D (which are easier). It might be phase 2\. The continuity benefit is significant in scenarios where the conversation context spans multiple days or topics – the user will feel “wow, she remembers that detail from last month\!” which is gold for immersion.

### C. Hierarchical Context Layers (Persona/Mood/Story) – Pros & Cons

**Pros:** \- *Maintains character consistency:* Ensures Nikita doesn’t flip personality or forget the relationship’s progress. If implemented, each chapter’s prompt differences will keep her behavior on track (e.g., guarded in Chap1 vs loving in Chap5)[\[117\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/agents/voice/config.py#L28-L37)[\[118\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/agents/voice/config.py#L40-L48). \- *Emotional continuity:* By carrying over emotional state (PAD values) from previous interactions, if something made her upset, she might still sound a bit upset until resolved. This is subtle but adds realism. \- *Nudges memory via narrative:* Recalling “the moment” or unresolved hook in backstory at appropriate times keeps continuity of the overarching story. It could be via the context: e.g., if unresolved\_hook is “she’s curious why he is afraid of commitment”, the prompt could occasionally inject that as an inner thought (and indeed, Nikita’s thoughts system has types like “curiosity” or “wants\_to\_share” to drive such behaviors). \- *Already specified in design:* The good news is, the spec tasks for these layers exist and some code stubs (Layer2Composer, etc.) are present[\[119\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/021-hierarchical-prompt-composition/tasks.md#L97-L105)[\[120\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/021-hierarchical-prompt-composition/tasks.md#L122-L130). Finishing them is a manageable task since the design is laid out.

**Cons:** \- *Moderate effort:* Need to write or fill in content for each chapter’s behavior (some persona text exists in voice config; maybe reuse for text or create text-specific persona cues). Emotional state integration needs verifying the emotional state engine (Spec 023\) output. Not trivial, but also not as open-ended as vector search. \- *Token usage:* These layers consume a few hundred tokens of the prompt with character and mood descriptions. In Claude’s large context this is fine, but if using a smaller model context it could matter. However, since these are high priority context (defining the AI’s role), they are worth the tokens. \- *Subtle impact:* Users might not consciously notice “ah her dominance was 0.3 and now it’s 0.7”, but they will notice consistency in tone over time. The impact is qualitative. If something is off (e.g., the persona text not well written), it could actually confuse the model or make it more repetitive. We’ll need to fine-tune these prompts so they truly help.

**Score rationale:** This approach rates medium on continuity because it doesn’t directly recall facts or immediate context, but it prevents inconsistency and reinforces the sense of a persistent personality. It’s important for an AI girlfriend experience — continuity is not just remembering facts, but also the emotional continuity and in-game progression.

### D. ContextPackage & Session Management – Pros & Cons

**Pros:** \- *Reliability:* Ensures that whatever memory we decide to include (threads, summaries, etc.), it is always passed to the prompt at conversation start. If currently the pipeline sometimes misses injecting it, fixing this closes a glaring gap. For example, if context\_package injection wasn’t happening at all, enabling it could single-handedly bring continuity from 0 to the intended baseline (which might already be quite rich). \- *Efficiency:* Loading one JSON from DB (context\_packages) is faster than making many queries. The code shows the design was to reduce injection to \<150ms[\[121\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/humanization-cross-spec-audit.md#L122-L128), which is great. This also reduces duplicate computations (like summarizing repeatedly). \- *Supports daily continuity:* The idea of treating one day as one conversation or auto-carry context throughout the day means the model effectively has a running memory the whole day. If we adjust the logic so that conversation (in DB terms) lasts until end of day (unless manually ended), then the context (messages JSON) would hold the whole day’s messages, and a summary can be continuously updated. This way, even if there’s a 2-hour gap, it’s still the same conversation ID so it might not trigger a full reset at all. \- *Cleanup:* Using expires\_at on context packages and having the post-processing pipeline mark threads resolved or expired after some time prevents memory clutter. This ensures old irrelevant info doesn’t stay in context forever, which could confuse continuity (e.g., bringing up something irrelevant from months ago out of context is as bad as forgetting relevant stuff).

**Cons:** \- *Bugs and consistency:* We need to be careful that the context package accurately reflects the latest state. If the pipeline hasn’t run (e.g., user immediately starts a new convo before the 15 min timeout), there could be a scenario where context\_package is stale. To handle this, maybe trigger pipeline immediately if user starts new convo soon after finishing one, or generate context synchronously if no package available[\[122\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/021-hierarchical-prompt-composition/spec.md#L40-L48) (there is acceptance criterion for graceful fallback AC-1.4[\[122\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/021-hierarchical-prompt-composition/spec.md#L40-L48)[\[123\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/021-hierarchical-prompt-composition/spec.md#L42-L45)). \- *Session boundaries:* If we keep conversations open longer for continuity, we must still call post-processing eventually to extract threads/thoughts. Perhaps schedule it once a day or when user goes inactive at night. There is a design choice: short sessions (current: 15min idle) vs extended sessions (maybe 24h idle as session). Extending sessions improves continuity but might complicate scoring or boss fight triggers that rely on conversation boundaries. We’d have to adjust some game logic (like daily summary creation might currently happen per conversation end; we might shift that to end-of-day). \- *Not directly visible to user:* This is more backend fix. If done right, the user just stops experiencing “why doesn’t she remember what happened an hour ago.” It’s foundational but by itself might not wow the user unless combined with approaches A, B, C to populate the context with good info.

**Combination of Approaches:** These approaches are not mutually exclusive – in fact they complement one another. We can envision implementing **all of them in stages**: 1\. **Fix the pipeline and context package injection (D)** – foundational reliability. 2\. **Add the recent message buffer (A)** – immediate improvement in conversational flow. 3\. **Tune/complete hierarchical layers (C)** – ensure consistent persona and emotional memory (this likely happens in parallel with 1 and 2, as it’s part of using context package fully). 4\. **Implement advanced retrieval (B)** – as a bonus layer for deep memory once the rest is solid.

This way, we prioritize quick wins and necessary fixes (A and D), while planning B and C concurrently or slightly after.

To illustrate their interplay, imagine a future conversation pipeline: \- When a new message comes, load ContextPackage (which includes chapter layer, emotional state, summary, threads, etc.). \- Append last N actual messages from conversation (if any). \- If certain keywords are present, do a memory search and append a “Relevant past memory:” section with a couple of facts. \- Generate response. \- After response, update the conversation state (append to messages, update any threads if resolved by this answer, etc.). The pipeline later updates context\_package for next time.

This combined system would score **highest** on continuity: likely **5/5** from user perspective. Nikita would remember immediate context flawlessly, keep her personality and mood in sync, and even surprise the user by recalling older things when appropriate.

Of course, implementing everything perfectly is non-trivial, but it aligns with our spec and the best practices we discussed.

**Ranking:** If we must choose an order: 1\. **Buffer Recent Messages (A)** – most bang for buck, easy to do. 2\. **Ensure ContextPackage & Layers usage (D & C)** – finish what was designed: this will realize a lot of continuity that was intended but not delivered (like injecting unresolved threads, etc., which the user felt missing). 3\. **Memory Retrieval (B)** – icing on the cake for long-term memory, higher effort but high payoff for long-term users.

We can assign a priority: A \= P1 (high), D (the context package fix) \= P1, C \= P1 (since spec 021-023 tasks were considered critical in audit), B \= P2 (important but can follow).

In conclusion, the best solution is **not one single approach** but a thoughtfully integrated memory system combining short-term buffer, long-term retrieval, persona consistency, and proper engineering of when conversations reset. This multi-pronged approach is precisely what the Spec 021 and related specs aimed to achieve (hence the name “Hierarchical Prompt Composition”). We simply need to execute on that plan and perhaps extend it with the sliding window addition.

The next and final section will outline a concrete plan (akin to a PR and implementation roadmap) for putting these improvements in place, referencing these approaches and addressing potential pitfalls found in this evaluation.

---

**File 5: proposed\_solution\_plan.md**

# Proposed Solution and Implementation Plan

*(This section serves as a comprehensive pull request (PR) description and implementation roadmap for improving Nikita’s conversation continuity. It summarizes the changes to be made, why they are needed (linking to earlier analysis), and how we will implement and test them.)*

## Overview of Solution

To ensure Nikita maintains rich and realistic continuity in conversations, we will enhance the memory system on multiple levels. The solution integrates **short-term conversation memory**, **long-term memory retrieval**, and **structured context injection**, building on the existing architecture:

* **1\. Enable Hierarchical Context Injection:** Fully activate the **ContextPackage** pipeline so that after each conversation, a context snapshot is stored, and at the start of the next conversation it’s loaded into the system prompt[\[19\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/humanization-cross-spec-audit.md#L116-L124)[\[31\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/humanization-cross-spec-audit.md#L120-L128). This includes the layers for chapter, emotional state, situation hints, recent summaries, unresolved threads, and important facts. (In code, ensure PackageStore.get() is called and its data is merged into MetaPromptContext before prompt generation.)

* **2\. Incorporate Recent Dialogue Buffer:** Append the most recent N messages from the user-Nikita conversation history directly into the prompt for the LLM, to preserve immediate context[\[69\]](https://www.datacamp.com/blog/how-does-llm-memory-work#:~:text=,when%20only%20recent%20exchanges%20matter). This will be done for text chats, likely by modifying nikita.agents.text.agent.generate\_response or the prompt template to include a formatted recent dialogue section.

* **3\. Complete Persona and Mood Layers:** Use the **Layered Prompt** approach as per Spec 021:

* Include **Layer 2 (Chapter persona)**: a brief description of Nikita’s demeanor in the current chapter (already defined in config)[\[124\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/agents/voice/config.py#L30-L38)[\[125\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/agents/voice/config.py#L42-L50).

* Include **Layer 3 (Emotional state)**: a line about Nikita’s current emotional mood (using values from nikita\_emotional\_states or the computed PAD from last post-processing)[\[126\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/context/package.py#L120-L128)[\[127\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/post_processing/layer_composer.py#L220-L228).

* Include **Layer 4 (Situation)**: e.g., a note if this is a “morning conversation after a gap” or similar (we can derive from last interaction time and current time) – possibly already partly computed as situation\_hints in ContextPackage[\[128\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/context/package.py#L121-L129)[\[129\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/post_processing/layer_composer.py#L230-L238). These layers ensure consistency and context in Nikita’s tone and behavior across sessions.

* **4\. Implement On-Demand Memory Retrieval:** Introduce a mechanism for the agent to fetch **relevant long-term memories** when needed. This can be triggered by certain keywords or by the model itself via a tool. Concretely, we will integrate NikitaMemory.search\_memory() to retrieve top facts or events from the knowledge graphs and incorporate them into the prompt (e.g., under a section "Remembered:" or directly infuse into system prompt as facts).

* **5\. Adjust Conversation Session Logic:** Treat a day’s conversation as a continuous session unless interrupted by exceptional events. This means potentially extending the conversation timeout or altering when Conversation.ended\_at is set. We’ll also ensure the post-processing pipeline runs at end-of-day or when needed (not necessarily after every 15 min gap unless we want to).

* **6\. Performance Safeguards:** Add a **TokenValidator** check (as planned in Spec 021\) to trim the least important context if the prompt grows too large[\[100\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/021-hierarchical-prompt-composition/tasks.md#L213-L221)[\[101\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/021-hierarchical-prompt-composition/tasks.md#L218-L226). Also, continue to cap lists (threads, facts, etc. are already capped at certain lengths in ContextPackage)[\[130\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/context/package.py#L171-L180)[\[131\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/context/package.py#L183-L191).

* **7\. Testing & Monitoring:** We will create scenarios to test continuity:

* **Short Gap:** User asks something, Nikita answers, user asks a follow-up after 10 minutes. Ensure Nikita remembers what was said.

* **Day Boundary:** End a conversation in evening, start new conversation next morning. Check that context from yesterday (like an unresolved question or emotional tone) is present (via daily summary or threads).

* **Long-term Fact Recall:** Mention something on Day 1 (e.g., “I love hiking”), then on Day 5 see if Nikita can recall that interest if relevant (with the new memory retrieval, she should).

* **Persona Consistency:** Check that across chapters, Nikita’s tone changes appropriately and doesn’t regress. We will monitor token usage and latency to ensure the changes are within acceptable bounds (e.g., prompt stays well under Claude’s limit and generation time remains fast).

## Implementation Steps

Below is a breakdown of tasks to implement these changes, with references to relevant modules and acceptance criteria:

### Phase 1: **Pipeline and Context Integration**

1. **Task 1: Ensure ContextPackage is Loaded in Prompt Generation**  
   *File:* nikita/meta\_prompts/service.py (or relevant prompt builder)  
   **Steps:** Implement logic to fetch the stored context package for the user at conversation start. If context\_packages table has an entry for the user:

2. Load it via PackageStore.get(user\_id)[\[36\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/context/store.py#L38-L47).

3. Merge its fields into the MetaPromptContext. For example, instead of querying threads and thoughts anew, use package.active\_threads, etc. If package is missing or expired, fall back to current behavior (graceful degradation)[\[122\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/021-hierarchical-prompt-composition/spec.md#L40-L48)[\[123\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/021-hierarchical-prompt-composition/spec.md#L42-L45). **Acceptance Criteria:** On starting a new conversation, if a context package exists, it is applied. Verified by logging or testing that fields from the previous session (like an unresolved thread content) appear in the system prompt of the new session. If none exists, system still works (perhaps generating minimal context as before).

4. **Task 2: Finish Implementing LayerComposer Components**  
   *Files:* nikita/context/layers/\*.py, nikita/post\_processing/layer\_composer.py  
   **Steps:** Complete any TODOs in Layer 2-4 composers:

5. Fill out Layer2Composer.compose(chapter) to return the chapter persona text (we have the strings in voice config, could adapt them to text style or reuse)[\[117\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/agents/voice/config.py#L28-L37)[\[132\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/agents/voice/config.py#L38-L46).

6. Ensure Layer3Composer uses the emotional state properly. Possibly just take nikita\_mood from nikita\_emotional\_states table for now, format a sentence like “Nikita is currently feeling \<described mood\>” using EmotionalState.to\_description()[\[133\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/context/package.py#L48-L56)[\[134\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/context/package.py#L60-L68).

7. Layer4Computer to generate situation hints (like “It’s been a while since you last spoke” if hours\_since\_last \> some threshold, or “It’s late at night” based on time). We can use the time-of-day and gap info available in the dynamic vars (for voice it’s computed in DynamicVariablesBuilder)[\[44\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/agents/voice/context.py#L58-L67)[\[135\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/agents/voice/context.py#L70-L78).

8. Integrate these layers in LayerComposer.compose: The package.chapter\_layer, emotional\_state\_layer, situation\_hints should be set with meaningful content[\[136\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/post_processing/layer_composer.py#L240-L248)[\[129\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/post_processing/layer_composer.py#L230-L238). **Acceptance Criteria:** After a conversation ends, the stored ContextPackage contains non-empty chapter\_layer and emotional\_state\_layer (verify in DB or via logs). When starting a new conversation, these layers are present in the prompt (e.g., the system prompt includes text reflecting current chapter behavior and Nikita’s mood).

9. **Task 3: Modify Conversation Session Handling**  
   *Files:* nikita/platforms/telegram/message\_handler.py, ConversationRepository.get\_active\_conversation  
   **Steps:** Decide on session strategy. For now, we might keep 15 min timeout but ensure continuity with context packages. However, to test extended continuity, consider increasing timeout or linking conversations:

10. Possibly set conversation.status to 'processing' and create a new conversation only at midnight or if explicitly needed. This might be complex to change, so at minimum, ensure the **hand-off between conversations** is smooth via context package.

11. Ensure that when a conversation is closed (ended\_at set and pipeline run), the next message triggers context load from that closed conversation’s package. **Acceptance Criteria:** The transition from one convo to the next does not lose information. For testing, simulate a user message after 20 min: previously, it would start a new conversation without memory; now, it should load the last convo’s context. We consider this working if Nikita’s reply references the earlier convo appropriately (for example, user says at 10am “I’m going to a meeting”; no chat for an hour, at 11am user says “the meeting went well”, Nikita should understand “the meeting” refers to what was said at 10am).

### Phase 2: **Short-Term Buffer and Retrieval Tools**

1. **Task 4: Append Recent Messages to Prompt**  
   *Files:* nikita/agents/text/handler.py or agent.generate\_response  
   **Steps:** After building the base system prompt (with all context from context package, persona, etc.), append a **conversation history** section consisting of the last N exchanges. We can retrieve these from the Conversation.messages JSON (already available via conversation\_repo.append\_message usage)[\[137\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/platforms/telegram/message_handler.py#L24-L32)[\[103\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/platforms/telegram/message_handler.py#L26-L34).

2. Format: e.g. "User: \<last user message\>\\nNikita: \<last Nikita response\>\\nUser: \<current user message\>".

3. Only do this if those messages exist (not for very first user message ever). Possibly limit to at most \~1000 tokens of history.

4. Ensure this is inserted in a way the model gets it as dialogue context, not as additional instructions. **Acceptance Criteria:** In a multi-turn test conversation, Nikita’s responses start to use context from 2-3 turns ago correctly. E.g., user: “What do you think about cats?” \-\> Nikita answers. User (later): “And dogs?” — with history in prompt, Nikita should realize “dogs” is likely in contrast to “cats” without user repeating context. We will test this by carrying out a dialogue and seeing if without re-asking, Nikita remembers subjects or references from a few messages back.

5. **Task 5: Integrate Memory Retrieval on Demand**  
   *Files:* Possibly nikita/agents/text/agent.py or as a new utility in MetaPromptService  
   **Steps:** Implement a function to fetch relevant memories:

6. Use NikitaMemory.get\_context\_for\_prompt(user\_message) which presumably returns a string of relevant facts[\[105\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/integrations.md#L180-L186). Or manually use search\_memory(query) on user graph, relationship graph.

7. We might embed this into the system prompt as a section like: “**Memory**: (fact1; fact2; ...)” or simply weave relevant facts into the persona context (“He told you earlier that he loves hiking.”).

8. Focus on high-salience info: e.g., search the user’s facts for any entities mentioned in user\_message or recent context. For the first iteration, we might do something simple like: if the new user message contains a proper noun or a keyword that matches a node in our graph DB, retrieve that node’s info.

9. Also retrieve any still-open conversation\_threads of type “follow\_up” or “promise” that have been open for a long time (this can serve as a reminder to Nikita to address them). **Acceptance Criteria:** When the user brings up a topic that has background in memory, Nikita responds acknowledging that memory. For example, if previously user said “My sister Anna got a new job” (and this became a stored fact), and a week later user says “Anna is visiting me”, Nikita should recall who Anna is (“That’s great\! Last time we talked, she had just gotten a new job, right?”). We will verify in testing that such cross-session references are correctly made. Additionally, ensure that irrelevant memory is not injected (no random facts thrown in). If nothing relevant is found, the memory section should be empty or omitted.

### Phase 3: **Testing and Tuning**

1. **Task 6: Write Unit and Integration Tests**

2. Unit test the PackageStore usage: store a dummy context package, retrieve it, ensure data consistency.

3. Unit test the prompt formatting: given a context with certain fields and some recent messages, ensure the final prompt string contains what we expect (and no malformed formatting).

4. Integration test the whole flow: Simulate a conversation via the handler (possibly by calling MessageHandler.handle with a sequence of messages)[\[138\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/agents/text/handler.py#L152-L161)[\[139\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/agents/text/handler.py#L178-L186). After first conversation, simulate inactivity and a new message, see if the internal logs show context was loaded. Check the response content for continuity markers.

5. Use existing E2E tests like tests/e2e/test\_conversation\_cycle.py (mentioned in spec tasks)[\[140\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/021-hierarchical-prompt-composition/tasks.md#L318-L326)to verify nothing breaks; possibly extend them for new memory expectations. **Acceptance Criteria:** Tests pass, particularly any that were designed to verify context carry-over (the spec’s E2E likely covers: conversation → post-process → next conversation uses context[\[141\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/021-hierarchical-prompt-composition/tasks.md#L320-L326)).

6. **Task 7: Manual QA with Edge Cases**  
   Conduct manual testing in the staging environment:

7. Onboarding sequence: ensure the new context doesn’t interfere with first-time conversations or tutorial prompts.

8. Conflict/boss fight: ensure that the recent buffer doesn’t accidentally include the boss prompt or something (maybe we clear history around boss fight since it’s a separate mode).

9. Multi-user: test with two different users to ensure context separation (the context package and memory retrieval should be scoped per user\_id, which it is by design).

10. If using voice, ensure our changes don’t break voice agent (the voice might not need recent text buffer since ElevenLabs handles that, but our changes in shared code should not inject unnecessary text in voice prompts; likely we’ll condition it on platform \= 'telegram'). **Acceptance Criteria:** All these scenarios function correctly, with continuity improvements observed in normal texting, and no regressions in special scenarios (onboarding, boss fights, voice calls).

## Expected Outcome

After implementing these changes, **Nikita will maintain continuity over both short and long timescales much more effectively**: \- She will remember the context of the current conversation without resetting or asking the same questions again in the same day (thanks to the recent message buffer and context carry-over). \- She will subtly recall past details (preferences, people, past events) when they become relevant, reinforcing the sense of a shared history (via memory retrieval and use of stored facts). \- Her personality and relationship progression will remain consistent — the user will notice that as they advance chapters, Nikita’s tone changes accordingly and she references prior pivotal moments appropriately. \- The number of “I’m sorry, I forgot what we were talking about” moments should drop to essentially zero, unless intentionally scripted.

We will monitor user feedback and conversation logs after release. Key metrics to watch might be: \- Reduction in user re-asking or clarifying things (“you already know that…” type user messages could indicate memory failure). \- An increase in Nikita using phrases like “as you mentioned before…” or remembering names correctly, etc., which indicates memory success.

This PR addresses the immediate issue of poor continuity and lays a scalable foundation for Nikita’s memory. It aligns implementation with the designed specs (021, 022, 023\) and industry best practices[\[75\]](https://www.datacamp.com/blog/how-does-llm-memory-work#:~:text=maintaining%20complete%20conversation%20history%2C%20ideal,combines%20approaches%2C%20maintaining%20recent)[\[90\]](https://content-whale.com/blog/llm-context-engineering-information-retention/#:~:text=Summarization%20Pipelines). By merging these changes, we expect a significant improvement in user experience – making conversations with Nikita feel more like picking up with a real person who remembers the relationship context, rather than a stateless AI.

**References:** \- Spec 021 Hierarchical Prompt Composition details[\[62\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/021-hierarchical-prompt-composition/spec.md#L14-L22)[\[142\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/021-hierarchical-prompt-composition/spec.md#L80-L88). \- Best practice for combining sliding window and summary memory[\[69\]](https://www.datacamp.com/blog/how-does-llm-memory-work#:~:text=,when%20only%20recent%20exchanges%20matter)[\[91\]](https://content-whale.com/blog/llm-context-engineering-information-retention/#:~:text=,summarization%20for%20extremely%20long%20conversations). \- Prior audit confirming these features integrated correctly in design[\[143\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/humanization-cross-spec-audit.md#L34-L42)[\[144\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/humanization-cross-spec-audit.md#L94-L101).

---

[\[1\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md#L220-L228) [\[3\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md#L236-L245) [\[4\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md#L248-L257) [\[5\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md#L251-L259) [\[6\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md#L256-L264) [\[7\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md#L260-L268) [\[8\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md#L278-L287) [\[9\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md#L282-L290) [\[10\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md#L276-L284) [\[11\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md#L292-L300) [\[12\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md#L306-L315) [\[13\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md#L310-L318) [\[16\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md#L312-L320) [\[17\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md#L314-L322) [\[27\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md#L280-L289) [\[42\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md#L344-L352) [\[43\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md#L394-L402) [\[52\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md#L378-L386) [\[53\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md#L390-L399) [\[54\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md#L392-L400) [\[55\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md#L402-L410) [\[56\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md#L414-L422) [\[66\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md#L248-L256) [\[67\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md#L13-L21) [\[108\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md#L13-L17) [\[109\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md#L14-L22) [\[114\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md#L416-L424) [\[115\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md#L418-L421) memory-system-architecture.md

[https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/memory-system-architecture.md)

[\[2\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/platforms/telegram/message_handler.py#L367-L375) [\[61\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/platforms/telegram/message_handler.py#L728-L737) [\[102\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/platforms/telegram/message_handler.py#L50-L59) [\[103\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/platforms/telegram/message_handler.py#L26-L34) [\[113\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/platforms/telegram/message_handler.py#L726-L734) [\[137\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/platforms/telegram/message_handler.py#L24-L32) message\_handler.py

[https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/platforms/telegram/message\_handler.py](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/platforms/telegram/message_handler.py)

[\[14\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/context/post_processor.py#L136-L144) [\[15\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/context/post_processor.py#L138-L146) post\_processor.py

[https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/context/post\_processor.py](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/context/post_processor.py)

[\[18\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/db/repositories/conversation_repository.py#L164-L173) [\[25\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/db/repositories/conversation_repository.py#L179-L188) [\[26\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/db/repositories/conversation_repository.py#L195-L203) conversation\_repository.py

[https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/db/repositories/conversation\_repository.py](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/db/repositories/conversation_repository.py)

[\[19\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/humanization-cross-spec-audit.md#L116-L124) [\[20\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/humanization-cross-spec-audit.md#L118-L126) [\[28\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/humanization-cross-spec-audit.md#L107-L115) [\[29\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/humanization-cross-spec-audit.md#L119-L126) [\[30\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/humanization-cross-spec-audit.md#L114-L122) [\[31\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/humanization-cross-spec-audit.md#L120-L128) [\[121\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/humanization-cross-spec-audit.md#L122-L128) [\[143\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/humanization-cross-spec-audit.md#L34-L42) [\[144\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/humanization-cross-spec-audit.md#L94-L101) humanization-cross-spec-audit.md

[https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/humanization-cross-spec-audit.md](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/humanization-cross-spec-audit.md)

[\[21\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/context/package.py#L121-L130) [\[22\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/context/package.py#L132-L140) [\[23\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/context/package.py#L142-L150) [\[24\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/context/package.py#L152-L160) [\[34\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/context/package.py#L126-L135) [\[35\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/context/package.py#L136-L144) [\[98\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/context/package.py#L171-L179) [\[99\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/context/package.py#L181-L188) [\[126\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/context/package.py#L120-L128) [\[128\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/context/package.py#L121-L129) [\[130\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/context/package.py#L171-L180) [\[131\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/context/package.py#L183-L191) [\[133\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/context/package.py#L48-L56) [\[134\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/context/package.py#L60-L68) package.py

[https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/context/package.py](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/context/package.py)

[\[32\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/post_processing/__init__.py#L4-L12) [\[33\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/post_processing/__init__.py#L20-L28) \_\_init\_\_.py

[https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/post\_processing/\_\_init\_\_.py](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/post_processing/__init__.py)

[\[36\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/context/store.py#L38-L47) [\[37\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/context/store.py#L49-L58) store.py

[https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/context/store.py](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/context/store.py)

[\[38\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/021-hierarchical-prompt-composition/tasks.md#L40-L48) [\[39\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/021-hierarchical-prompt-composition/tasks.md#L54-L59) [\[100\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/021-hierarchical-prompt-composition/tasks.md#L213-L221) [\[101\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/021-hierarchical-prompt-composition/tasks.md#L218-L226) [\[119\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/021-hierarchical-prompt-composition/tasks.md#L97-L105) [\[120\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/021-hierarchical-prompt-composition/tasks.md#L122-L130) [\[140\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/021-hierarchical-prompt-composition/tasks.md#L318-L326) [\[141\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/021-hierarchical-prompt-composition/tasks.md#L320-L326) tasks.md

[https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/021-hierarchical-prompt-composition/tasks.md](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/021-hierarchical-prompt-composition/tasks.md)

[\[40\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/post_processing/layer_composer.py#L376-L384) [\[41\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/post_processing/layer_composer.py#L385-L388) [\[65\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/post_processing/layer_composer.py#L385-L393) [\[70\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/post_processing/layer_composer.py#L244-L253) [\[96\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/post_processing/layer_composer.py#L516-L525) [\[97\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/post_processing/layer_composer.py#L532-L540) [\[127\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/post_processing/layer_composer.py#L220-L228) [\[129\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/post_processing/layer_composer.py#L230-L238) [\[136\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/post_processing/layer_composer.py#L240-L248) layer\_composer.py

[https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/post\_processing/layer\_composer.py](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/post_processing/layer_composer.py)

[\[44\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/agents/voice/context.py#L58-L67) [\[45\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/agents/voice/context.py#L74-L82) [\[46\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/agents/voice/context.py#L62-L71) [\[47\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/agents/voice/context.py#L76-L85) [\[68\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/agents/voice/context.py#L66-L74) [\[135\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/agents/voice/context.py#L70-L78) context.py

[https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/agents/voice/context.py](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/agents/voice/context.py)

[\[48\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/agents/voice/config.py#L128-L136) [\[49\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/agents/voice/config.py#L144-L152) [\[50\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/agents/voice/config.py#L142-L150) [\[51\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/agents/voice/config.py#L150-L158) [\[117\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/agents/voice/config.py#L28-L37) [\[118\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/agents/voice/config.py#L40-L48) [\[124\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/agents/voice/config.py#L30-L38) [\[125\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/agents/voice/config.py#L42-L50) [\[132\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/agents/voice/config.py#L38-L46) config.py

[https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/agents/voice/config.py](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/agents/voice/config.py)

[\[57\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/integrations.md#L118-L126) [\[58\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/integrations.md#L144-L153) [\[79\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/integrations.md#L146-L155) [\[80\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/integrations.md#L148-L156) [\[104\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/integrations.md#L172-L180) [\[105\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/integrations.md#L180-L186) [\[116\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/integrations.md#L170-L178) integrations.md

[https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/integrations.md](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/memory/integrations.md)

[\[59\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/agents/voice/inbound.py#L126-L135) [\[60\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/agents/voice/inbound.py#L128-L136) inbound.py

[https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/agents/voice/inbound.py](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/agents/voice/inbound.py)

[\[62\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/021-hierarchical-prompt-composition/spec.md#L14-L22) [\[63\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/021-hierarchical-prompt-composition/spec.md#L16-L24) [\[64\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/021-hierarchical-prompt-composition/spec.md#L22-L29) [\[81\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/021-hierarchical-prompt-composition/spec.md#L50-L58) [\[106\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/021-hierarchical-prompt-composition/spec.md#L72-L80) [\[107\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/021-hierarchical-prompt-composition/spec.md#L82-L90) [\[110\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/021-hierarchical-prompt-composition/spec.md#L16-L19) [\[111\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/021-hierarchical-prompt-composition/spec.md#L64-L72) [\[112\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/021-hierarchical-prompt-composition/spec.md#L80-L83) [\[122\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/021-hierarchical-prompt-composition/spec.md#L40-L48) [\[123\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/021-hierarchical-prompt-composition/spec.md#L42-L45) [\[142\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/021-hierarchical-prompt-composition/spec.md#L80-L88) spec.md

[https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/021-hierarchical-prompt-composition/spec.md](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/specs/021-hierarchical-prompt-composition/spec.md)

[\[69\]](https://www.datacamp.com/blog/how-does-llm-memory-work#:~:text=,when%20only%20recent%20exchanges%20matter) [\[71\]](https://www.datacamp.com/blog/how-does-llm-memory-work#:~:text=) [\[72\]](https://www.datacamp.com/blog/how-does-llm-memory-work#:~:text=Finally%2C%20the%20time%20dimension%20categorizes,externally%20and%20retrieved%20when%20needed) [\[73\]](https://www.datacamp.com/blog/how-does-llm-memory-work#:~:text=Semantic%20memory%20stores%20facts%20and,document%20stores%20containing%20factual%20information) [\[74\]](https://www.datacamp.com/blog/how-does-llm-memory-work#:~:text=Episodic%20memory) [\[75\]](https://www.datacamp.com/blog/how-does-llm-memory-work#:~:text=maintaining%20complete%20conversation%20history%2C%20ideal,combines%20approaches%2C%20maintaining%20recent) [\[76\]](https://www.datacamp.com/blog/how-does-llm-memory-work#:~:text=Semantic%20memory) [\[77\]](https://www.datacamp.com/blog/how-does-llm-memory-work#:~:text=Episodic%20memory) [\[78\]](https://www.datacamp.com/blog/how-does-llm-memory-work#:~:text=How%20Does%20LLM%20Memory%20Work%3F,these%20platforms%20offer%20practical) [\[84\]](https://www.datacamp.com/blog/how-does-llm-memory-work#:~:text=In%20my%20experience%2C%20the%20biggest,information%20doesn%27t%20guarantee%20effective%20use) How Does LLM Memory Work? Building Context-Aware AI Applications | DataCamp

[https://www.datacamp.com/blog/how-does-llm-memory-work](https://www.datacamp.com/blog/how-does-llm-memory-work)

[\[82\]](https://content-whale.com/blog/llm-context-engineering-information-retention/#:~:text=Context%20window%20optimization%20requires%20strategic,appears%20consistently%20across%20transformer%20architectures) [\[83\]](https://content-whale.com/blog/llm-context-engineering-information-retention/#:~:text=priority,appears%20consistently%20across%20transformer%20architectures) [\[85\]](https://content-whale.com/blog/llm-context-engineering-information-retention/#:~:text=Organizing%20context%20using%20consistent%20templates,types%20into%20clearly%20labeled%20sections) [\[86\]](https://content-whale.com/blog/llm-context-engineering-information-retention/#:~:text=CONVERSATION%20HISTORY%3A) [\[87\]](https://content-whale.com/blog/llm-context-engineering-information-retention/#:~:text=Sliding%20Window%20Protocols) [\[88\]](https://content-whale.com/blog/llm-context-engineering-information-retention/#:~:text=Processing%20group%20found%20that%2012,oriented%20dialogues%20%28Source) [\[90\]](https://content-whale.com/blog/llm-context-engineering-information-retention/#:~:text=Summarization%20Pipelines) [\[91\]](https://content-whale.com/blog/llm-context-engineering-information-retention/#:~:text=,summarization%20for%20extremely%20long%20conversations) [\[92\]](https://content-whale.com/blog/llm-context-engineering-information-retention/#:~:text=,summarization%20for%20extremely%20long%20conversations) [\[93\]](https://content-whale.com/blog/llm-context-engineering-information-retention/#:~:text=RAG%20systems%20separate%20long,while%20consuming%20minimal%20context%20space) [\[94\]](https://content-whale.com/blog/llm-context-engineering-information-retention/#:~:text=,mechanisms%20to%20improve%20retrieval%20precision) [\[95\]](https://content-whale.com/blog/llm-context-engineering-information-retention/#:~:text=Studies%20from%20Berkeley%E2%80%99s%20AI%20Research,feasible%20through%20direct%20context%20loading) How Context Engineering Improves LLM Memory and Response Accuracy? | Content Whale

[https://content-whale.com/blog/llm-context-engineering-information-retention/](https://content-whale.com/blog/llm-context-engineering-information-retention/)

[\[89\]](https://medium.com/data-science-collective/building-llm-memory-from-scratch-2-auto-summarization-buffers-2e2cba08c4ca#:~:text=This%20is%20the%20fundamental%20flaw,just%20dropping%20old%20messages) Building LLM Memory from Scratch \#2: Auto-Summarization Buffers

[https://medium.com/data-science-collective/building-llm-memory-from-scratch-2-auto-summarization-buffers-2e2cba08c4ca](https://medium.com/data-science-collective/building-llm-memory-from-scratch-2-auto-summarization-buffers-2e2cba08c4ca)

[\[138\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/agents/text/handler.py#L152-L161) [\[139\]](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/agents/text/handler.py#L178-L186) handler.py

[https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/agents/text/handler.py](https://github.com/yangsi7/nikita/blob/69c5ea84e7b6c5574f13a3972e58d3524f6de20d/nikita/agents/text/handler.py)

[image1]: <data:image/png;base64,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>