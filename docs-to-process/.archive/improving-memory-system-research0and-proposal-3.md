

## Whatâ€™s actually happening today (from the code)

### Texting (Telegram) runtime: effectively stateless per turn

**Path:** `platforms/telegram/message_handler.py` â†’ `agents/text/handler.py` â†’ `agents/text/agent.py`

What happens each incoming text:

1. Telegram handler fetches/creates a `conversations` row (status `active`) and appends the user message into `conversations.messages`.
2. It calls the text agent to generate a reply.
3. **The LLM call is made with only the userâ€™s latest message** and a generated system prompt.
4. The assistant reply is appended back into `conversations.messages`.

**Critical continuity issue:** the agent call does **not** include message history (`message_history`) â€” so the model literally doesnâ€™t see the previous messages unless they happen to be re-described in the system prompt.

PydanticAI explicitly supports passing prior turns as `message_history` to preserve multi-turn continuity across separate calls. ([ai.pydantic.dev][1])

### Voice runtime: continuity depends on a cached system prompt + tools

Voice is different:

* On call start, the ElevenLabs session uses `users.cached_voice_prompt` (or a fallback default).
* During the call, ElevenLabs can use **server tools** (`get_context`, `search_memory`, etc.) to fetch memory.
* On call end (webhook), the code runs the legacy post-processor pipeline and then regenerates + caches the voice system prompt.

So voice can feel continuous **if**:

* the cached prompt is fresh, and
* the graphs/summaries are being updated, and
* the tools are being used by the voice agent.

---

## Why it feels like â€œtexting starts from zeroâ€ (root causes)

### 1) Text LLM calls have no short-term conversation buffer

For text, each LLM response is generated without providing prior turns (no rolling window, no â€œtodayâ€™s transcriptâ€, no in-call state). So unless your meta prompt manages to â€œreconstructâ€ continuity from summaries/graphs, the model is blind.

This alone explains the â€œwe reset quicklyâ€ feeling.

### 2) The intended â€œpost-processing updates memory â†’ next prompt includes itâ€ loop is fragile

Your architecture expectation is correct in spirit: summarize + extract memory after sessions, then inject it into future prompts.

In this repo snapshot, that loop is **not reliable for text**, because:

* **Text post-processing is triggered only by the background task route** (`/tasks/process-conversations`) + stale-session detection.
* If the scheduler isnâ€™t running (pg_cron or whatever calls it), stale conversations donâ€™t get processed â†’ graphs/summaries/threads donâ€™t update â†’ next prompt has little to work with.
* Even when it runs, the repo contains two pipelines:

  * **Legacy pipeline** (`nikita/context/post_processor.py`) â€” full featured, used by voice.
  * **New â€œpost_processingâ€ pipeline** (`nikita/post_processing/*`) â€” incomplete in this snapshot (stubby summary/touchpoint parts, plus API mismatches).

So: texting can end up with **no short-term buffer** *and* **no updated long-term memory**, which is a perfect recipe for â€œamnesia.â€

### 3) Your meta prompt *expects* â€œlast conversation summaryâ€ â€” but it wasnâ€™t being populated

The system prompt meta-template includes `{{last_conversation_summary}}`, but `MetaPromptService` wasnâ€™t filling that field from the DB, so even the â€œbridgeâ€ between conversations was often missing.

---

## Where memory lives in your schema vs where code actually reads/writes it

Hereâ€™s the practical truth table:

### Written every message

* `conversations.messages` âœ… (text + voice)
* `conversations.last_message_at` âœ…

### Written after a conversation ends (post-processing)

* `daily_summaries` âœ… **only if legacy post-processor runs**
* `conversation_threads`, `nikita_thoughts` âœ… **only if legacy post-processor runs**
* Graph memory (Graphiti/Neo4j) âœ… **only if the graph updater runs successfully**
* `context_packages` âš ï¸ pipeline exists, but not the source of truth for the running prompts right now (text/voice prompt gen isnâ€™t consuming it)

### Read at prompt-generation time

* `daily_summaries`, `conversation_threads`, `nikita_thoughts`, `user_backstories`, `user_profiles`, metrics/emotional state âœ…
* Graph memory via Graphiti search âœ…
* **Recent transcript / message history** âŒ (this is the big gap)

---

## Diagram: where continuity breaks

```text
TEXT (Telegram)
User msg
  -> append to conversations.messages
  -> build system prompt (meta prompt / memory retrieval)
  -> LLM run(user_message ONLY)   <-- NO message history passed
  -> append assistant reply
  -> (later) background job may post-process stale conversation (often not guaranteed)

VOICE (ElevenLabs)
Call start
  -> use users.cached_voice_prompt (generated previously)
  -> during call: tools can fetch memory
Call end webhook
  -> legacy post-processor updates summaries/threads/graphs
  -> regenerate + cache users.cached_voice_prompt
```

---

## Best-practice memory model for â€œhuman continuityâ€

Thereâ€™s a fairly convergent set of best practices across modern agent systems:

### 1) Use **tiered memory** (short â†’ mid â†’ long)

* **Short-term / working memory:** a rolling buffer of recent turns (or at minimum â€œtodayâ€™s turnsâ€). This is what prevents the â€œresetâ€ feeling.
* **Episodic memory:** summaries of sessions / key moments (â€œwhat happened, why it mattered emotionallyâ€), often stored as events + timestamps.
* **Semantic memory:** stable facts/preferences/relationships (â€œuser likes Xâ€, â€œweâ€™re datingâ€, â€œtheir friend is Yâ€).
* **Procedural memory:** â€œhow Nikita behavesâ€ (persona + style rules).

This mirrors common patterns in research and tooling:

* **Generative Agents**: store experiences, retrieve relevant memories, and use reflection to synthesize higher-level beliefs. ([arXiv][2])
* **MemGPT**: argues for hierarchical memory to overcome limited context windows and support long-running conversations. ([arXiv][3])
* LangChain/LangGraphâ€™s memory guidance similarly splits semantic vs episodic vs procedural, and emphasizes that memory formation + retrieval policies are application-specific. ([langchain-ai.github.io][4])

### 2) Donâ€™t rely on summaries alone for immediacy

Summaries are great for compression, but they are *not* a substitute for a rolling window of actual dialogue for the last N turns / last day. Humans remember the last thing you said â€” not just a therapistâ€™s intake note.

### 3) Make â€œpromises / cliffhangers / open loopsâ€ first-class

You already have `conversation_threads` and `nikita_thoughts`. Those are exactly the â€œsticky continuity hooksâ€ that make a companion feel alive â€” but only if theyâ€™re reliably created/updated and consistently injected.

### 4) Retrieval should be â€œcue + time + importanceâ€

In practice:

* **Cue:** similarity to current message (â€œJapan tripâ€ pulls Japan memories)
* **Time:** boost recent memories
* **Importance:** boost â€œhigh emotional impactâ€ and â€œcommitmentsâ€

LangMem explicitly calls out importance and recency/frequency (â€œstrengthâ€) as common retrieval factors. ([langchain-ai.github.io][4])

---

## Approaches to fix continuity (ranked with constructive criticism)

Scoring: 1â€“5 (higher is better).
Dimensions: **Continuity**, **Latency/Cost**, **Complexity**, **Robustness**, **Debuggability**

### A) Add a short-term â€œtoday bufferâ€ (message_history) + keep long-term retrieval

**What:** Always pass a rolling window of recent turns (and optionally â€œtodayâ€™s turnsâ€) into the LLM call. Keep Graphiti + summaries as long-term memory.

* Continuity: **5**
* Latency/Cost: **4** (more tokens, but predictable)
* Complexity: **2**
* Robustness: **4** (works even if post-processing lags)
* Debuggability: **4**

**Criticism:** token growth if youâ€™re careless; needs trimming policy.

âœ… **This is the single biggest â€œstop the amnesiaâ€ lever.**

### B) Context packages (hierarchical prompt composition) + cached daily prompt

**What:** Precompute a daily â€œcontext packageâ€ (persona + relationship + key memories + open threads) and inject it, plus a small rolling buffer.

* Continuity: **4**
* Latency/Cost: **5** (fast at runtime)
* Complexity: **4**
* Robustness: **3** (depends on background processing)
* Debuggability: **5** (great if you log package snapshots)

**Criticism:** if packages arenâ€™t refreshed reliably, you get â€œstale personality.â€

### C) Full â€œGenerative Agents / MemGPT-styleâ€ memory manager (reflection + consolidation)

**What:** After sessions, run a reflection step that writes: events, relationships, emotional moments, and updated beliefs; retrieval uses cue+time+importance.

* Continuity: **5**
* Latency/Cost: **3**
* Complexity: **5**
* Robustness: **3â€“4** (depends on ops discipline)
* Debuggability: **3** unless heavily instrumented

**Criticism:** can become a mini research project; easy to overbuild.

**My recommendation:** **A now**, **B next**, **C selectively** once the system is stable.

---

## The PR I generated (code + diagram) â€” fixes the core continuity break

### What this PR does

1. **Text agent now passes a â€œtodayâ€ rolling message window as `message_history`** into the PydanticAI `Agent.run(...)`.

   * This gives immediate continuity even if summaries/graphs are delayed.
2. **Uses the userâ€™s timezone to compute â€œtodayâ€** (where possible) when building the day-buffer.
3. **Text prompt generation now receives `conversation_id`** so generated prompts can be traced per conversation.
4. **Restores text background processing to the legacy PostProcessor** (same one voice uses), because the new pipeline in this snapshot isnâ€™t reliable enough to drive memory continuity.
5. **MetaPromptService now fills `last_conversation_summary`** from the most recent processed conversation, matching what the system prompt template expects.
6. Adds a code-level system diagram doc and logs the â€œUnderstandingâ€ event.

### Patch file

[Download the PR patch](sandbox:/mnt/data/nikita_memory_continuity_pr.patch)

### Files changed (high level)

* `nikita/agents/text/agent.py`
* `nikita/agents/text/handler.py`
* `nikita/platforms/telegram/message_handler.py`
* `nikita/api/routes/tasks.py`
* `nikita/db/repositories/conversation_repository.py`
* `nikita/meta_prompts/service.py`
* `docs/2026-01-19-memory-audit/system_diagram.md`
* `event-stream.md`

### Test plan you can run quickly

* **Continuity within a session:** send 5â€“10 messages; Nikita should reference earlier details without needing â€œremind her.â€
* **Continuity after a break:** wait >15 minutes, send a new message; she should still know what happened earlier *today*.
* **Post-processing:** hit `/tasks/process-conversations` (or ensure pg_cron runs it) and verify:

  * `conversations.status` â†’ `processed`
  * `daily_summaries.summary_text` updated
  * `conversation_threads` / `nikita_thoughts` created
  * next system prompt includes `last_conversation_summary`

---

## What Iâ€™d do next (small, high ROI)

1. **Make text â€œsession boundariesâ€ explicit**: if a conversation is stale when a new message arrives, close the old one and start a new one *but still include the today-buffer*.
   (Your system already has a 15-min concept in `SessionDetector`; the runtime path doesnâ€™t currently enforce it.)
2. **Ensure the background job is unquestionably running** (pg_cron or external scheduler). Without it, youâ€™ll always be fighting memory drift.
3. **Add a â€œcommitments & callbacksâ€ section that is always injected** (threads + promises), with strict token budgeting.
4. **Unify voice + text prompt inputs**: same memory sources, same structure, same logging.

The universe is cruel and loves nothing more than an AI companion that forgets your birthday. The fix is not â€œone more clever prompt.â€ Itâ€™s making sure the model reliably sees (a) the last turns, (b) todayâ€™s arc, and (c) the durable relationship facts â€” every time.

If you apply the patch, the â€œreset after a short timeâ€ symptom for texting should drop dramatically, because weâ€™re no longer asking the model to do telepathy with no transcript.

[1]: https://ai.pydantic.dev/agents/ "https://ai.pydantic.dev/agents/"
[2]: https://arxiv.org/abs/2304.03442 "[2304.03442] Generative Agents: Interactive Simulacra of Human Behavior"
[3]: https://arxiv.org/abs/2310.08560 "[2310.08560] MemGPT: Towards LLMs as Operating Systems"
[4]: https://langchain-ai.github.io/langmem/concepts/conceptual_guide/ "Core Concepts"



Got it. I cracked open the repo (from the ZIP you provided) and followed the actual runtime paths for **texting** and **voice**, plus the **postâ€‘processing / memory** pipeline. The continuity problems youâ€™re seeing arenâ€™t a vibe issue â€” theyâ€™re concrete wiring gaps and a couple of â€œthis looks implemented but isnâ€™t actually in the loopâ€ situations.

Below is the **investigation summary so far**, the **most likely causes of â€œreset to zeroâ€**, and what Iâ€™ve already started fixing in a PR branch locally. Whatâ€™s still incomplete (docs + diagrams + PRD + final PR patch) is listed at the end.

---

## 1) How the system *currently* works (as implemented)

### Text (Telegram) runtime path

**Telegram message â†’ DB conversation append â†’ text agent â†’ response â†’ DB append**

Key files:

* `nikita/platforms/telegram/message_handler.py`
* `nikita/agents/text/handler.py`
* `nikita/agents/text/agent.py`
* `nikita/context/template_generator.py`
* `nikita/meta_prompts/service.py`

**Critical finding:**
Every *individual* message is treated as a fresh inference call with **no message history passed into the LLM**.

In `nikita/agents/text/agent.py`, the `Agent.run(...)` call is executed with only the current user message and a system prompt. No prior turns are provided as `message_history`, and no explicit transcript section was being injected either.

That alone can cause â€œwho are you again?â€ symptoms **within the same conversation window**, depending on how rich the system prompt is.

---

### Voice runtime path

Voice has two parallel memory flows:

#### A) Preâ€‘call voice prompt

Voice pre-call uses a cached system prompt for speed:

* `nikita/agents/voice/inbound.py`
* Uses: `users.cached_voice_prompt`

This is intentionally done to avoid LLM calls during ElevenLabs pre-call webhook.

#### B) Inâ€‘call retrieval tools

Voice agent can call server tools during the call:

* `nikita/agents/voice/server_tools.py`
* `get_context`, `get_memory`, etc.

**Critical mismatch I found:**
The voice `get_context` tool reads `daily_summaries.nikita_summary_text`, but both the â€œlegacyâ€ postâ€‘processor and the newer summary generator populate **`daily_summaries.summary_text`**. Result: voice tool often returns `today_summary = null` even when daily summary exists.

That weakens continuity during voice calls and makes voice â€œfeel behindâ€ texting.

---

## 2) When is a conversation â€œoverâ€ and how continuity is *supposed* to transfer?

Thereâ€™s a session timeout mechanism:

* `ConversationRepository.get_stale_active_conversations(stale_minutes=15)`
* `detect_stale_sessions(...)` marks them as `processing`
* then a cron / task route processes them

The intended continuity transfer is:

* extract facts / entities / summary
* update Graphiti memory graphs
* persist threads/thoughts/key moments
* update daily summaries
* then next conversation uses that memory in prompt generation

This is exactly what you described (post-processing generates new context, new system prompt is richer).

---

## 3) Why â€œstarting from zeroâ€ actually happens (root causes)

### Root Cause A â€” **Text agent has no working-memory / transcript injection**

Even if longâ€‘term memory works perfectly, the text agent is stateless turn-to-turn unless you provide:

* recent transcript
* or message_history structure

As implemented, text agent **does not include todayâ€™s transcript or even the active conversation transcript** in the LLM call.

So: â€œcontinuity collapses quicklyâ€ is expected behavior.

---

### Root Cause B â€” **The postâ€‘processing cron route was wired to an incomplete pipeline**

This is the big one for â€œafter a little time we reset to zero.â€

The cron route `POST /tasks/process-conversations` was importing:

```py
from nikita.post_processing import process_conversations
```

That â€œnewâ€ pipeline (`nikita/post_processing/adapter.py`) is currently not feature-complete and doesnâ€™t match the tables / message structure reliably.

Symptoms if that route runs:

* conversations get marked `processing`
* but the pipeline **does not reliably produce the same memory artifacts**
* and in some cases can fail / no-op
* meaning the next conversation starts with **no updated memory context**

Meanwhile voice post-processing uses the legacy pipeline:

* `nikita/context/post_processor.py`
  and therefore voice tends to be â€œmore memory-richâ€ than text.

This mismatch is the kind of â€œit worksâ€¦ except when it doesnâ€™tâ€¦ except itâ€™s every timeâ€ that ruins continuity.

---

### Root Cause C â€” **Voice tool uses wrong summary column**

As noted, `server_tools.get_context` uses `nikita_summary_text` but the system writes `summary_text`. So voiceâ€™s â€œday recapâ€ memory is missing even when it exists.

---

## 4) What I changed already (local PR in progress)

I started implementing fixes in the repo locally (no GitHub PR possible from here, but I can generate a patch + PR description).

### âœ… Fix 1: Task post-processing now uses the legacy full extraction pipeline

Changed `/tasks/process-conversations` to import:

```py
from nikita.context.post_processor import process_conversations
```

Why: this pipeline actually:

* extracts entities + facts
* creates conversation threads + nikita thoughts
* updates Graphiti graphs meaningfully
* generates real summaries (not stub)
* marks conversations processed correctly

This aligns texting post-processing with voice post-processing.

---

### âœ… Fix 2: Voice `get_context` now reads `summary_text` (fallback to `nikita_summary_text`)

Updated:

* `nikita/agents/voice/server_tools.py`

So voice tool returns today/week summaries correctly.

---

### âœ… Fix 3: MetaPromptService now injects â€œlast conversation summaryâ€ + recent transcript block

Updated:

* `nikita/meta_prompts/service.py`

Two improvements:

1. it now loads `last_conversation_summary` (previously always None)
2. it appends a trimmed **â€œRecent Conversation (last ~24h, verbatim)â€** block to the generated system prompt output, capped by tier and token budget.

This gives the model real working memory without requiring a full conversion to `message_history`.

---

### âœ… Fix 4: After processing a text conversation, refresh cached voice prompt

In `/tasks/process-conversations`, after successful processing, I added logic to:

* gather affected user_ids
* generate a **critical-tier** system prompt via `MetaPromptService`
* store into `users.cached_voice_prompt`, `cached_voice_prompt_at`

This fixes crossâ€‘modality continuity (text â†’ voice).

---

## 5) Best practices research (started, with sources)

I began pulling high-signal references for â€œagent memory typesâ€ and continuity architectures:

* **PydanticAI message_history behavior** (important because it changes system prompt regeneration rules)
  Source: PydanticAI docs on message history
  [https://ai.pydantic.dev/message-history/](https://ai.pydantic.dev/message-history/)

* **Generative Agents (Park et al., 2023)** â€” memory stream, retrieval, reflection loop
  [https://arxiv.org/abs/2304.03442](https://arxiv.org/abs/2304.03442)

* **MemGPT** â€” hierarchical memory manager, working vs archival
  [https://arxiv.org/abs/2310.08560](https://arxiv.org/abs/2310.08560)

* **A-MEM (2024)** â€” agent memory taxonomy and strategies
  [https://arxiv.org/abs/2402.10010](https://arxiv.org/abs/2402.10010)

* **LlamaIndex agent memory overview** (practical patterns)
  [https://www.llamaindex.ai/blog/enhancing-ai-agent-reliability-with-memory](https://www.llamaindex.ai/blog/enhancing-ai-agent-reliability-with-memory)

These will feed directly into the PRD and design options scoring.

---

## 6) Whatâ€™s still incomplete (but clearly scoped)

You asked for a full â€œcoding agent context packâ€ output. I have not yet produced the full document set and diagrams â€” I focused first on isolating the real runtime gaps and starting a concrete PR fix.

### Remaining deliverables I still need to generate inside the repo:

1. **Architecture & continuity docs**

   * â€œCurrent Text Flowâ€
   * â€œCurrent Voice Flowâ€
   * â€œConversation lifecycle (active â†’ stale â†’ processing â†’ processed)â€
   * â€œMemory layers present vs missingâ€

2. **Diagrams**

   * sequence diagrams for text and voice
   * memory flow diagram (DB + Graphiti + prompts + post-processing)
   * context injection stack (working memory vs episodic vs semantic etc.)

3. **PRD**

   * explicit requirements: daily continuity, short-term transcript, long-term memory
   * performance budgets
   * prompt layering rules
   * observability & metrics
   * rollout plan

4. **Design options + scoring**

   * â€œappend transcriptâ€ (what I implemented)
   * â€œtrue message_history statefulnessâ€ (PydanticAI)
   * â€œcontext_packages-based hierarchical prompt compositionâ€
   * hybrid approaches
   * scored across: continuity, latency, cost, complexity, safety, debuggability

5. **Comprehensive PR output**

   * final patch (`.patch`)
   * PR title + description
   * testing notes
   * migration notes if needed

---

## The weird truth in one sentence

Text continuity is currently bad because **(1) turn-to-turn history isnâ€™t provided** and **(2) the post-processing cron path for text was wired to an incomplete pipeline**, so sessions end and memory doesnâ€™t reliably transfer.

Which is the software equivalent of: â€œWe gave her a hippocampus, but forgot to connect it to the brainstem.â€ ğŸ§ âš¡

---

If you want to keep momentum: the next step is me generating the **docs + diagrams + PRD + ranked options**, and then Iâ€™ll produce the **final unified patch + PR description** as files in `docs/<session-id>/...` inside the repo.
